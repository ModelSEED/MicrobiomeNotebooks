{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Important links\n",
    "* https://github.com/ModelSEED/MicrobiomeNotebooks.git\n",
    "* Workspace with Cliff's MAGs: https://narrative.kbase.us/narrative/155805\n",
    "* Workspace with additional redundant MAGs: https://narrative.kbase.us/narrative/163264\n",
    "* Workspace with pangenome enhanced MAGs: https://narrative.kbase.us/narrative/187797\n",
    "* FAA of representative sequences: /scratch/fliu/data/cliff/mmseqs_ani_prob_rep_genome.faa  \n",
    "* Cluster genome mapping: /scratch/fliu/data/cliff/mmseqs_ani_prob.json  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading hit data from json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python version 3.11.1\n",
      "KBBaseModules 0.0.1\n",
      "modelseedpy 0.3.3\n",
      "cobrakbase 0.3.1\n",
      "Output files printed to:/scratch/chenry/MicrobiomeNotebooks/Cliff/nboutput when using KBDevUtils.output_dir\n",
      "ModelSEED: /scratch/shared//sdkmount/kb_sdk_home/run_local/workdir/tmp/\n"
     ]
    }
   ],
   "source": [
    "%run cliffcommutil.py\n",
    "with open(\"/scratch/fliu/data/cliff/mmseqs_ani_prob_v2.json\", 'r') as f:\n",
    "    hit_data = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing hits for close genome list and establishing thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output files printed to:/scratch/chenry/MicrobiomeNotebooks/Cliff/nboutput when using KBDevUtils.output_dir\n",
      "ModelSEED: /scratch/shared//sdkmount/kb_sdk_home/run_local/workdir/tmp/\n"
     ]
    }
   ],
   "source": [
    "%run cliffcommutil.py\n",
    "mag_ani_data = {}\n",
    "mag_thresholds = {}\n",
    "mag_genomes = {}\n",
    "mag_hit_distribution = {}\n",
    "max_bins = 27\n",
    "min_sim = 74\n",
    "for protein in hit_data:\n",
    "    for mag in hit_data[protein]:\n",
    "        if mag not in mag_ani_data:\n",
    "            mag_ani_data[mag] = {}\n",
    "            mag_hit_distribution[mag] = [0] * max_bins\n",
    "        for hit in hit_data[protein][mag]:\n",
    "            genome = hit.split(\":\")[0]\n",
    "            if hit_data[protein][mag][hit] < 100 and hit_data[protein][mag][hit] >= min_sim:\n",
    "                if genome not in mag_ani_data[mag]:\n",
    "                    mag_hit_distribution[mag][int(hit_data[protein][mag][hit]-min_sim)] += 1\n",
    "                mag_ani_data[mag][genome] = hit_data[protein][mag][hit]\n",
    "util.save(\"mag_ani_data\",mag_ani_data)\n",
    "util.save(\"mag_hit_distribution\",mag_hit_distribution)\n",
    "records = []\n",
    "for mag in mag_hit_distribution:\n",
    "    if mag not in mag_thresholds:\n",
    "        mag_thresholds[mag] = {\"threshold\":0,\"threshold_count\":0}\n",
    "    record = {\"mag\":mag}\n",
    "    threshold = 0\n",
    "    for i in range(max_bins):\n",
    "        record[\"ani_\" + str(min_sim+i)] = mag_hit_distribution[mag][i]\n",
    "    threshold_count = 0\n",
    "    for i in range(max_bins):\n",
    "        index = max_bins-1-i  \n",
    "        if mag_hit_distribution[mag][index] > 0 and (threshold == 0 or threshold == min_sim+index+1) and threshold_count <= 4 and (threshold_count == 0 or mag_hit_distribution[mag][index]/threshold_count < 5):\n",
    "            threshold_count += mag_hit_distribution[mag][index]\n",
    "            threshold = min_sim+index\n",
    "    mag_thresholds[mag][\"threshold\"] = threshold\n",
    "    mag_thresholds[mag][\"threshold_count\"] = threshold_count\n",
    "    if threshold_count == 1:\n",
    "        new_threshold = 0\n",
    "        additional_count = 0\n",
    "        start = max_bins-(threshold-min_sim)\n",
    "        for i in range(start,max_bins,1):\n",
    "            index = max_bins-1-i\n",
    "            if mag_hit_distribution[mag][index] > 0 and (new_threshold == 0 or new_threshold == min_sim+index+1) and additional_count <= 4 and (additional_count == 0 or mag_hit_distribution[mag][index]/additional_count < 5):\n",
    "                additional_count += mag_hit_distribution[mag][index]\n",
    "                new_threshold = min_sim+index\n",
    "        if new_threshold != 0:\n",
    "            record[\"new_threshold\"] = new_threshold\n",
    "            record[\"new_threshold_count\"] = additional_count\n",
    "            if (threshold-new_threshold)<=10 or threshold != 100:\n",
    "                mag_thresholds[mag][\"threshold\"] = new_threshold\n",
    "                mag_thresholds[mag][\"threshold_count\"] = threshold_count+additional_count\n",
    "    record[\"threshold\"] = threshold\n",
    "    record[\"threshold_count\"] = threshold_count\n",
    "    records.append(record)\n",
    "for mag in mag_ani_data:\n",
    "    mag_genomes[mag] = {}\n",
    "    for genome in mag_ani_data[mag]:\n",
    "        if mag_ani_data[mag][genome] >= mag_thresholds[mag][\"threshold\"]:\n",
    "            mag_genomes[mag][genome] = mag_ani_data[mag][genome]\n",
    "df = pd.DataFrame.from_records(records)\n",
    "df.to_csv(util.output_dir+\"/mag_hit_distribution.csv\",index=False)\n",
    "util.save(\"mag_thresholds\",mag_thresholds)\n",
    "util.save(\"mag_genomes\",mag_genomes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assigning thresholds manually (not needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run cliffcommutil.py\n",
    "mag_thresholds = util.load(\"mag_thresholds\")\n",
    "mag_ani_data = util.load(\"mag_ani_data\")\n",
    "mag_genomes = {}\n",
    "for mag in mag_ani_data:\n",
    "    mag_genomes[mag] = {}\n",
    "    for genome in mag_ani_data[mag]:\n",
    "        if mag_ani_data[mag][genome] >= mag_thresholds[mag][\"threshold\"]:\n",
    "            mag_genomes[mag][genome] = mag_ani_data[mag][genome]\n",
    "    mag_thresholds[mag][\"threshold_count\"] = len(mag_genomes[mag])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting workspace IDs for MAGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output files printed to:/scratch/chenry/MicrobiomeNotebooks/Cliff/nboutput when using KBDevUtils.output_dir\n",
      "ModelSEED: /scratch/shared//sdkmount/kb_sdk_home/run_local/workdir/tmp/\n"
     ]
    }
   ],
   "source": [
    "%run cliffcommutil.py\n",
    "mag_wsids = {}\n",
    "mag_list = []\n",
    "mags = util.msrecon.kbase_api.list_objects(155805, object_type=\"KBaseGenomes.Genome\", include_metadata=False)\n",
    "mag_list = mags\n",
    "for item in mags:\n",
    "    mag_wsids[item[1]] = item[7]\n",
    "mags = util.msrecon.kbase_api.list_objects(163264, object_type=\"KBaseGenomes.Genome\", include_metadata=False)\n",
    "for item in mags:\n",
    "    mag_wsids[item[1]] = item[7]\n",
    "util.save(\"mag_wsids\",mag_wsids)\n",
    "util.save(\"mag_list\",mag_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identifying supplemental proteins for MAGs based on thresholds and hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output files printed to:/scratch/chenry/MicrobiomeNotebooks/Cliff/nboutput when using KBDevUtils.output_dir\n",
      "ModelSEED: /scratch/shared//sdkmount/kb_sdk_home/run_local/workdir/tmp/\n"
     ]
    }
   ],
   "source": [
    "%run cliffcommutil.py\n",
    "mag_protein_supplements = {}\n",
    "mag_thresholds = util.load(\"mag_thresholds\")\n",
    "mag_genomes = util.load(\"mag_genomes\")\n",
    "mag_list = util.load(\"mag_list\")\n",
    "mag_wsids = util.load(\"mag_wsids\")\n",
    "all_mag_deep_data = {}\n",
    "for mag in mag_wsids:\n",
    "    all_mag_deep_data[mag] = {}\n",
    "for protein in hit_data:\n",
    "    for mag in hit_data[protein]:\n",
    "        if mag_thresholds[mag][\"threshold\"] > 0:\n",
    "            nr_mags_found = {}\n",
    "            rejected_mags_found = {}\n",
    "            genomes_found = {}\n",
    "            all_mag_deep_data[mag][protein] = {\n",
    "                \"self\":False,\n",
    "                \"total\":[0,0],\n",
    "                \"nr_mags\":[0,0],\n",
    "                \"rejected_mags\":[0,0],\n",
    "                \"genomes\":[0,0]\n",
    "            }\n",
    "            for hit in hit_data[protein][mag]:\n",
    "                (genome,gene) = hit.split(\":\")\n",
    "                if genome == \"self\":\n",
    "                    all_mag_deep_data[mag][protein][\"self\"] = True\n",
    "                elif genome in mag_list:\n",
    "                    if genome not in nr_mags_found:\n",
    "                        all_mag_deep_data[mag][protein][\"total\"][0] += 1\n",
    "                        all_mag_deep_data[mag][protein][\"nr_mags\"][0] += 1\n",
    "                        if hit_data[protein][mag][hit] >= mag_thresholds[mag][\"threshold\"]:\n",
    "                            if genome not in mag_genomes[mag]:\n",
    "                                print(genome+\":\"+mag+\":\"+str(hit_data[protein][mag][hit])+\"/\"+str(mag_thresholds[mag][\"threshold\"]))\n",
    "                            all_mag_deep_data[mag][protein][\"total\"][1] += 1\n",
    "                            all_mag_deep_data[mag][protein][\"nr_mags\"][1] += 1\n",
    "                        nr_mags_found[genome] = hit_data[protein][mag][hit]\n",
    "                    elif nr_mags_found[genome] != hit_data[protein][mag][hit]:\n",
    "                        print(\"Warning: different similarity values for the same genome\")\n",
    "                elif genome in mag_wsids:\n",
    "                    if genome not in rejected_mags_found:\n",
    "                        all_mag_deep_data[mag][protein][\"total\"][0] += 1\n",
    "                        all_mag_deep_data[mag][protein][\"rejected_mags\"][0] += 1\n",
    "                        if hit_data[protein][mag][hit] >= mag_thresholds[mag][\"threshold\"]:\n",
    "                            if genome not in mag_genomes[mag]:\n",
    "                                print(genome+\":\"+mag+\":\"+str(hit_data[protein][mag][hit])+\"/\"+str(mag_thresholds[mag][\"threshold\"]))\n",
    "                            all_mag_deep_data[mag][protein][\"total\"][1] += 1\n",
    "                            all_mag_deep_data[mag][protein][\"rejected_mags\"][1] += 1\n",
    "                        rejected_mags_found[genome] = hit_data[protein][mag][hit]\n",
    "                    elif rejected_mags_found[genome] != hit_data[protein][mag][hit]:\n",
    "                        print(\"Warning: different similarity values for the same genome\")\n",
    "                else:\n",
    "                    if genome not in genomes_found:\n",
    "                        all_mag_deep_data[mag][protein][\"total\"][0] += 1\n",
    "                        all_mag_deep_data[mag][protein][\"genomes\"][0] += 1\n",
    "                        if hit_data[protein][mag][hit] >= mag_thresholds[mag][\"threshold\"]:\n",
    "                            if genome not in mag_genomes[mag]:\n",
    "                                print(genome+\":\"+mag+\":\"+str(hit_data[protein][mag][hit])+\"/\"+str(mag_thresholds[mag][\"threshold\"]))\n",
    "                            all_mag_deep_data[mag][protein][\"total\"][1] += 1\n",
    "                            all_mag_deep_data[mag][protein][\"genomes\"][1] += 1\n",
    "                        genomes_found[genome] = hit_data[protein][mag][hit]\n",
    "                    elif genomes_found[genome] != hit_data[protein][mag][hit]:\n",
    "                        print(\"Warning: different similarity values for the same genome\")\n",
    "            #We only add supplemental proteins for a family that does not already have a protein in the MAG\n",
    "            if not all_mag_deep_data[mag][protein][\"self\"]:\n",
    "                if mag not in mag_protein_supplements:\n",
    "                    mag_protein_supplements[mag] = {}\n",
    "                mag_protein_supplements[mag][protein] = [all_mag_deep_data[mag][protein][\"total\"][1],all_mag_deep_data[mag][protein][\"nr_mags\"][1],all_mag_deep_data[mag][protein][\"rejected_mags\"][1]]\n",
    "for mag in all_mag_deep_data:\n",
    "    util.save(\"deepdata/\"+mag,all_mag_deep_data[mag])\n",
    "util.save(\"mag_protein_supplements\",mag_protein_supplements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load functional data (not needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output files printed to:/scratch/chenry/MicrobiomeNotebooks/Cliff/nboutput when using KBDevUtils.output_dir\n",
      "ModelSEED: /scratch/shared//sdkmount/kb_sdk_home/run_local/workdir/tmp/\n"
     ]
    }
   ],
   "source": [
    "%run cliffcommutil.py\n",
    "function_hit_data = json.load(open('/home/fliu/cliff_mags/data/annotation_ani_prob_lo_85.json'))\n",
    "mag_function_supplements = {}\n",
    "mag_thresholds = util.load(\"mag_thresholds\")\n",
    "mag_list = util.load(\"mag_list\")\n",
    "mag_wsids = util.load(\"mag_wsids\")\n",
    "all_func_mag_deep_data = {}\n",
    "for mag in mag_wsids:\n",
    "    all_func_mag_deep_data[mag] = {}\n",
    "for protein in function_hit_data:\n",
    "    for mag in function_hit_data[protein]:\n",
    "        nr_mags_found = {}\n",
    "        rejected_mags_found = {}\n",
    "        genomes_found = {}\n",
    "        all_func_mag_deep_data[mag][protein] = {\n",
    "            \"self\":False,\n",
    "            \"total\":[0,0],\n",
    "            \"nr_mags\":[0,0],\n",
    "            \"rejected_mags\":[0,0],\n",
    "            \"genomes\":[0,0]\n",
    "        }\n",
    "        for hit in function_hit_data[protein][mag]:\n",
    "            (genome,gene) = hit.split(\":\")\n",
    "            if genome == \"self\":\n",
    "                all_func_mag_deep_data[mag][protein][\"self\"] = True\n",
    "            elif genome in mag_list:\n",
    "                if genome not in nr_mags_found:\n",
    "                    all_func_mag_deep_data[mag][protein][\"total\"][0] += 1\n",
    "                    all_func_mag_deep_data[mag][protein][\"nr_mags\"][0] += 1\n",
    "                    if function_hit_data[protein][mag][hit] >= mag_thresholds[mag][\"threshold\"]/100:\n",
    "                        all_func_mag_deep_data[mag][protein][\"total\"][1] += 1\n",
    "                        all_func_mag_deep_data[mag][protein][\"nr_mags\"][1] += 1\n",
    "                    nr_mags_found[genome] = function_hit_data[protein][mag][hit]\n",
    "                elif nr_mags_found[genome] != function_hit_data[protein][mag][hit]:\n",
    "                    print(\"Warning: different similarity values for the same genome\")\n",
    "            elif genome in mag_wsids:\n",
    "                if genome not in rejected_mags_found:\n",
    "                    all_func_mag_deep_data[mag][protein][\"total\"][0] += 1\n",
    "                    all_func_mag_deep_data[mag][protein][\"rejected_mags\"][0] += 1\n",
    "                    if function_hit_data[protein][mag][hit] >= mag_thresholds[mag][\"threshold\"]/100:\n",
    "                        all_func_mag_deep_data[mag][protein][\"total\"][1] += 1\n",
    "                        all_func_mag_deep_data[mag][protein][\"rejected_mags\"][1] += 1\n",
    "                    rejected_mags_found[genome] = function_hit_data[protein][mag][hit]\n",
    "                elif rejected_mags_found[genome] != function_hit_data[protein][mag][hit]:\n",
    "                    print(\"Warning: different similarity values for the same genome\")\n",
    "            else:\n",
    "                if genome not in genomes_found:\n",
    "                    all_func_mag_deep_data[mag][protein][\"total\"][0] += 1\n",
    "                    all_func_mag_deep_data[mag][protein][\"genomes\"][0] += 1\n",
    "                    if function_hit_data[protein][mag][hit] >= mag_thresholds[mag][\"threshold\"]/100:\n",
    "                        all_func_mag_deep_data[mag][protein][\"total\"][1] += 1\n",
    "                        all_func_mag_deep_data[mag][protein][\"genomes\"][1] += 1\n",
    "                    genomes_found[genome] = function_hit_data[protein][mag][hit]\n",
    "                elif genomes_found[genome] != function_hit_data[protein][mag][hit]:\n",
    "                    print(\"Warning: different similarity values for the same genome\")\n",
    "        #We only add supplemental proteins for a family that does not already have a protein in the MAG\n",
    "        if not all_func_mag_deep_data[mag][protein][\"self\"]:\n",
    "            if mag not in mag_function_supplements:\n",
    "                mag_function_supplements[mag] = {}\n",
    "            mag_function_supplements[mag][protein] = [all_func_mag_deep_data[mag][protein][\"total\"][1],all_func_mag_deep_data[mag][protein][\"nr_mags\"][1],all_func_mag_deep_data[mag][protein][\"rejected_mags\"][1]]\n",
    "for mag in mag_function_supplements:\n",
    "    util.save(\"funcdeepdata/\"+mag,all_func_mag_deep_data[mag])\n",
    "util.save(\"mag_function_supplements\",mag_function_supplements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing stats on additional proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salt_Pond_MetaGSF2_B_H2O_MG_DASTool_bins_metabat.8.contigs__.RAST 0.1 14737\n",
      "Salt_Pond_MetaG_R1_B_D1_MG_DASTool_bins_metabat.20.contigs__.RAST 0.1 3860\n",
      "Salt_Pond_MetaG_R2_B_D2_MG_DASTool_bins_concoct_out.4.contigs__.RAST 0.1 4004\n",
      "Salt_Pond_MetaG_R1_A_D2_MG_DASTool_bins_concoct_out.21.contigs__.RAST 0.1 4192\n",
      "Salt_Pond_MetaG_R1_C_D1_MG_DASTool_bins_metabat.31.contigs__.RAST 0.1 5106\n",
      "Salt_Pond_MetaG_R2_A_H2O_MG_DASTool_bins_concoct_out.29.contigs__.RAST 0.1 3670\n",
      "Salt_Pond_MetaG_R2_B_D2_MG_DASTool_bins_metabat.50.contigs__.RAST 0.1 4271\n",
      "Salt_Pond_MetaG_R1_B_D2_MG_DASTool_bins_metabat.18.contigs__.RAST 0.1 4144\n",
      "Salt_Pond_MetaG_R1_A_D1_MG_DASTool_bins.metabat.15.contigs__.RAST 0.1 1457\n",
      "Salt_Pond_MetaG_R2_C_D1_MG_DASTool_bins_concoct_out.88.contigs__.RAST 0.1 2330\n",
      "Salt_Pond_MetaG_R2_restored_C_black_MG_DASTool_bins_concoct_out.57.contigs__.RAST 0.1 1738\n",
      "Salt_Pond_MetaG_R2_A_D1_MG_DASTool_bins_metabat.10.contigs__.RAST 0.1 2713\n",
      "Salt_Pond_MetaGSF2_B_D1_MG_DASTool_bins_concoct_out.44.contigs__.RAST 0.1 3227\n",
      "Salt_Pond_MetaG_R2A_A_D1_MG_DASTool_bins_concoct_out.51.contigs__.RAST 0.1 1178\n",
      "Salt_Pond_MetaG_R2A_B_H2O_MG_DASTool_bins_concoct_out.69.contigs__.RAST 0.1 1707\n",
      "Salt_Pond_MetaG_R2A_C_H2O_MG_DASTool_bins_metabat.16.contigs__.RAST 0.1 552\n",
      "Salt_Pond_MetaG_R2A_C_D1_MG_DASTool_bins_metabat.18.contigs__.RAST 0.1 1601\n",
      "Salt_Pond_MetaG_R2A_B_H2O_MG_DASTool_bins_metabat.10.contigs__.RAST 0.1 526\n",
      "Salt_Pond_MetaGSF2_C_D2_MG_DASTool_bins_concoct_out.25.contigs__.RAST 0.1 4054\n",
      "Salt_Pond_MetaG_R2_A_D2_MG_DASTool_bins_concoct_out.67.contigs__.RAST 0.1 4079\n",
      "Salt_Pond_MetaG_R2_restored_DShore_MG_DASTool_bins_metabat.25.contigs__.RAST 0.1 1642\n",
      "Salt_Pond_MetaG_R1_A_D2_MG_DASTool_bins_metabat.50.contigs__.RAST 0.1 3743\n",
      "Salt_Pond_MetaG_R2_A_D1_MG_DASTool_bins_concoct_out.29.contigs__.RAST 0.1 2511\n",
      "Salt_Pond_MetaG_R1_B_D1_MG_DASTool_bins_metabat.38.contigs__.RAST 0.1 7764\n",
      "Salt_Pond_MetaG_R2_B_D2_MG_DASTool_bins_concoct_out.80.contigs__.RAST 0.1 1130\n",
      "Salt_Pond_MetaG_R1_B_H2O_MG_DASTool_bins_concoct_out.13.contigs__.RAST 0.1 1058\n",
      "Salt_Pond_MetaG_R2_C_D2_MG_DASTool_bins_concoct_out.45.contigs__.RAST 0.1 4868\n",
      "Salt_Pond_MetaG_R2_restored_DShore_MG_DASTool_bins_concoct_out.17.contigs__.RAST 0.15 12879\n",
      "Salt_Pond_MetaG_R2A_C_D1_MG_DASTool_bins_metabat.4.contigs__.RAST 0.1 11687\n",
      "Salt_Pond_MetaGSF2_B_H2O_MG_DASTool_bins_metabat.28.contigs__.RAST 0.1 2667\n",
      "Salt_Pond_MetaG_R2A_A_H2O_MG_DASTool_bins_concoct_out.62.contigs__.RAST 0.1 3462\n",
      "Salt_Pond_MetaG_R2A_C_D2_MG_DASTool_bins_concoct_out.42.contigs__.RAST 0.1 3490\n",
      "Salt_Pond_MetaGSF2_A_H2O_MG_DASTool_bins_metabat.14.contigs__.RAST 0.1 12246\n",
      "Salt_Pond_MetaG_R2A_C_D1_MG_DASTool_bins_metabat.17.contigs__.RAST 0.1 2856\n",
      "Salt_Pond_MetaGSF2_B_H2O_MG_DASTool_bins_concoct_out.91.contigs__.RAST 0.1 1994\n",
      "Salt_Pond_MetaG_R2_B_D1_MG_DASTool_bins_metabat.22.contigs__.RAST 0.1 12202\n",
      "Salt_Pond_MetaG_R1_B_D2_MG_DASTool_bins_metabat.34.contigs__.RAST 0.1 6051\n",
      "Salt_Pond_MetaGSF2_C_D2_MG_DASTool_bins_metabat.19.contigs__.RAST 0.1 17763\n",
      "Salt_Pond_MetaG_R2_restored_DShore_MG_DASTool_bins_concoct_out.37.contigs__.RAST 0.1 13720\n",
      "Salt_Pond_MetaG_R1_A_D2_MG_DASTool_bins_concoct_out.1.contigs__.RAST 0.1 770\n",
      "Salt_Pond_MetaG_R1_B_D1_MG_DASTool_bins_metabat.16.contigs__.RAST 0.1 7787\n",
      "Salt_Pond_MetaG_R2_B_D2_MG_DASTool_bins_metabat.52.contigs__.RAST 0.1 4103\n",
      "Salt_Pond_MetaG_R1_B_D2_MG_DASTool_bins_concoct_out.120.contigs__.RAST 0.1 4530\n",
      "Salt_Pond_MetaG_R1_C_D1_MG_DASTool_bins_metabat.27.contigs__.RAST 0.1 19814\n",
      "Salt_Pond_MetaG_R2_A_H2O_MG_DASTool_bins_concoct_out.45.contigs__.RAST 0.1 4509\n",
      "Salt_Pond_MetaG_R2_A_D1_MG_DASTool_bins_metabat.9.contigs__.RAST 0.1 10271\n",
      "Salt_Pond_MetaG_R2A_A_D1_MG_DASTool_bins_concoct_out.46.contigs__.RAST 0.1 8976\n",
      "Salt_Pond_MetaG_R2A_B_D2_MG_DASTool_bins_metabat.6.contigs__.RAST 0.1 9104\n",
      "Salt_Pond_MetaG_R2A_C_H2O_MG_DASTool_bins_concoct_out.67.contigs__.RAST 0.1 2987\n",
      "Salt_Pond_MetaG_R1_A_D1_MG_DASTool_bins.metabat.45.contigs__.RAST 0.1 6886\n",
      "Salt_Pond_MetaGSF2_C_D2_MG_DASTool_bins_concoct_out.15.contigs__.RAST 0.1 3915\n",
      "Salt_Pond_MetaG_R2A_C_D2_MG_DASTool_bins_concoct_out.69.contigs__.RAST 0.1 4127\n",
      "Salt_Pond_MetaG_R2_A_D2_MG_DASTool_bins_metabat.14.contigs__.RAST 0.1 7188\n",
      "Salt_Pond_MetaG_R2_restored_DShore_MG_DASTool_bins_metabat.23.contigs__.RAST 0.1 13334\n",
      "Salt_Pond_MetaG_R1_A_D2_MG_DASTool_bins_metabat.48.contigs__.RAST 0.1 3590\n",
      "Salt_Pond_MetaG_R1_B_D2_MG_DASTool_bins_concoct_out.73.contigs__.RAST 0.1 9701\n",
      "Salt_Pond_MetaG_R2_B_D2_MG_DASTool_bins_concoct_out.143.contigs__.RAST 0.1 4194\n",
      "Salt_Pond_MetaG_R1_B_D2_MG_DASTool_bins_metabat.78.contigs__.RAST 0.1 765\n",
      "Salt_Pond_MetaG_R1_C_H2O_MG_DASTool_bins_concoct_out.67.contigs__.RAST 0.1 7983\n",
      "Salt_Pond_MetaG_R2_A_D1_MG_DASTool_bins_metabat.12.contigs__.RAST 0.1 3828\n",
      "Salt_Pond_MetaG_R2_C_D2_MG_DASTool_bins_concoct_out.18.contigs__.RAST 0.1 4579\n",
      "Salt_Pond_MetaG_R2_restored_DShore_MG_DASTool_bins_concoct_out.40.contigs__.RAST 0.1 5366\n",
      "Salt_Pond_MetaG_R1_B_D2_MG_DASTool_bins_concoct_out.87.contigs__.RAST 0.1 4720\n",
      "Salt_Pond_MetaG_R2A_A_D2_MG_DASTool_bins_metabat.16.contigs__.RAST 0.1 2249\n",
      "Salt_Pond_MetaGSF2_B_H2O_MG_DASTool_bins_metabat.19.contigs__.RAST 0.1 1531\n",
      "Salt_Pond_MetaG_R2A_C_D1_MG_DASTool_bins_maxbin.009.contigs__.RAST 0.1 4035\n",
      "Salt_Pond_MetaGSF2_A_H2O_MG_DASTool_bins_concoct_out.33.contigs__.RAST 0.1 1541\n",
      "Salt_Pond_MetaG_R2_B_D1_MG_DASTool_bins_metabat.10.contigs__.RAST 0.1 8126\n",
      "Salt_Pond_MetaG_R2_B_H2O_MG_DASTool_bins_metabat.17.contigs__.RAST 0.1 4179\n",
      "Salt_Pond_MetaG_R1_A_D1_MG_DASTool_bins.metabat.51.contigs__.RAST 0.1 3660\n",
      "Salt_Pond_MetaG_R1_B_D2_MG_DASTool_bins_metabat.30.contigs__.RAST 0.1 6809\n",
      "Salt_Pond_MetaGSF2_C_D2_MG_DASTool_bins_concoct_out.42.contigs__.RAST 0.1 5624\n",
      "Salt_Pond_MetaG_R2_restored_C_black_MG_DASTool_bins_concoct_out.26.contigs__.RAST 0.1 1764\n",
      "Salt_Pond_MetaG_R2_restored_DShore_MG_DASTool_bins_concoct_out.68.contigs__.RAST 0.1 17088\n",
      "Salt_Pond_MetaG_R1_C_D1_MG_DASTool_bins_metabat.19.contigs__.RAST 0.1 1389\n",
      "Salt_Pond_MetaG_R2_B_D2_MG_DASTool_bins_metabat.44.contigs__.RAST 0.1 5876\n",
      "Salt_Pond_MetaG_R1_B_D2_MG_DASTool_bins_metabat.63.contigs__.RAST 0.1 1080\n",
      "Salt_Pond_MetaG_R2_A_D1_MG_DASTool_bins_metabat.7.contigs__.RAST 0.1 10147\n",
      "Salt_Pond_MetaG_R2A_B_H2O_MG_DASTool_bins_concoct_out.59.contigs__.RAST 0.1 8104\n",
      "Salt_Pond_MetaG_R2_restored_DShore_MG_DASTool_bins_concoct_out.2.contigs__.RAST 0.1 6308\n",
      "Salt_Pond_MetaGSF2_B_D2_MG_DASTool_bins_concoct_out.42.contigs__.RAST 0.1 11945\n",
      "Salt_Pond_MetaG_R2A_B_D1_MG_DASTool_bins_concoct_out.4.contigs__.RAST 0.1 11102\n",
      "Salt_Pond_MetaG_R2A_C_D2_MG_DASTool_bins_concoct_out.9.contigs__.RAST 0.1 7971\n",
      "Salt_Pond_MetaGSF2_A_D2_MG_DASTool_bins_concoct_out.8.contigs__.RAST 0.1 9888\n",
      "Salt_Pond_MetaG_R1_A_D1_MG_DASTool_bins.metabat.6.contigs__.RAST 0.1 1836\n",
      "Salt_Pond_MetaGSF2_A_D2_MG_DASTool_bins_concoct_out.13.contigs__.RAST 0.1 8654\n",
      "Salt_Pond_MetaG_R2_B_D2_MG_DASTool_bins_metabat.19.contigs__.RAST 0.1 4445\n",
      "Salt_Pond_MetaG_R2_A_D2_MG_DASTool_bins_concoct_out.19.contigs__.RAST 0.1 4457\n",
      "Salt_Pond_MetaG_R1_B_D2_MG_DASTool_bins_concoct_out.51.contigs__.RAST 0.1 4795\n",
      "Salt_Pond_MetaG_R2_restored_DShore_MG_DASTool_bins_concoct_out.7.contigs__.RAST 0.1 7154\n",
      "Salt_Pond_MetaG_R1_C_H2O_MG_DASTool_bins_metabat.29.contigs__.RAST 0.1 4688\n",
      "Salt_Pond_MetaG_R2_restored_H2O_MG_DASTool_bins_concoct_out.34.contigs__.RAST 0.1 1332\n",
      "Salt_Pond_MetaG_R2_B_D2_MG_DASTool_bins_concoct_out.32.contigs__.RAST 0.1 4894\n",
      "Salt_Pond_MetaG_R1_C_D1_MG_DASTool_bins_concoct_out.45.contigs__.RAST 0.1 10269\n",
      "Salt_Pond_MetaG_R2_C_D2_MG_DASTool_bins_concoct_out.100.contigs__.RAST 0.1 2770\n",
      "Salt_Pond_MetaG_R2A_A_H2O_MG_DASTool_bins_metabat.16.contigs__.RAST 0.1 1746\n",
      "Salt_Pond_MetaG_R2A_B_H2O_MG_DASTool_bins_metabat.42.contigs__.RAST 0.1 647\n",
      "Salt_Pond_MetaGSF2_A_H2O_MG_DASTool_bins_metabat.28.contigs__.RAST 0.1 8488\n",
      "Salt_Pond_MetaGSF2_C_D1_MG_DASTool_bins_concoct_out.13.contigs__.RAST 0.1 2035\n",
      "Salt_Pond_MetaG_R1_A_D2_MG_DASTool_bins_metabat.15.contigs__.RAST 0.1 10326\n",
      "Salt_Pond_MetaGSF2_B_H2O_MG_DASTool_bins_metabat.11.contigs__.RAST 0.1 10389\n",
      "Salt_Pond_MetaG_R1_A_D1_MG_DASTool_bins.metabat.26.contigs__.RAST 0.1 5937\n",
      "Salt_Pond_MetaG_R1_B_D1_MG_DASTool_bins_concoct_out.89.contigs__.RAST 0.1 4252\n",
      "Salt_Pond_MetaG_R1_B_D2_MG_DASTool_bins_metabat.28.contigs__.RAST 0.1 4318\n",
      "Salt_Pond_MetaG_R2_B_D1_MG_DASTool_bins_metabat.13.contigs__.RAST 0.1 4140\n",
      "Salt_Pond_MetaG_R2_restored_C_black_MG_DASTool_bins_concoct_out.25.contigs__.RAST 0.1 3750\n",
      "Salt_Pond_MetaGSF2_C_D2_MG_DASTool_bins_concoct_out.39.contigs__.RAST 0.1 2514\n",
      "Salt_Pond_MetaG_R2_restored_DShore_MG_DASTool_bins_concoct_out.89.contigs__.RAST 0.1 10168\n",
      "Salt_Pond_MetaG_R2_B_D2_MG_DASTool_bins_metabat.45.contigs__.RAST 0.1 3140\n",
      "Salt_Pond_MetaG_R2_A_D1_MG_DASTool_bins_maxbin.001.contigs__.RAST 0.1 2215\n",
      "Salt_Pond_MetaG_R1_B_D2_MG_DASTool_bins_metabat.37.contigs__.RAST 0.1 1956\n",
      "Salt_Pond_MetaG_R1_C_H2O_MG_DASTool_bins_metabat.23.contigs__.RAST 0.1 1715\n",
      "Salt_Pond_MetaG_R2_C_D1_MG_DASTool_bins_concoct_out.95.contigs__.RAST 0.15 7235\n",
      "Salt_Pond_MetaG_R2A_B_H2O_MG_DASTool_bins_concoct_out.80.contigs__.RAST 0.1 2464\n",
      "Salt_Pond_MetaGSF2_B_D1_MG_DASTool_bins_metabat.9.contigs__.RAST 0.1 9423\n",
      "Salt_Pond_MetaGSF2_A_D1_MG_DASTool_bins_concoct_out.23.contigs__.RAST 0.1 4575\n",
      "Salt_Pond_MetaG_R1_A_D1_MG_DASTool_bins.concoct_out.44.contigs__.RAST 0.1 2614\n",
      "Salt_Pond_MetaG_R2A_A_H2O_MG_DASTool_bins_metabat.49.contigs__.RAST 0.1 491\n",
      "Salt_Pond_MetaG_R2A_C_D2_MG_DASTool_bins_concoct_out.4.contigs__.RAST 0.1 3572\n",
      "Salt_Pond_MetaG_R2_B_D2_MG_DASTool_bins_metabat.38.contigs__.RAST 0.1 4211\n",
      "Salt_Pond_MetaG_R1_A_D2_MG_DASTool_bins_metabat.36.contigs__.RAST 0.1 3144\n",
      "Salt_Pond_MetaG_R1_B_D1_MG_DASTool_bins_metabat.58.contigs__.RAST 0.1 840\n",
      "Salt_Pond_MetaG_R1_B_H2O_MG_DASTool_bins_metabat.11.contigs__.RAST 0.1 5495\n",
      "Salt_Pond_MetaG_R2_A_H2O_MG_DASTool_bins_concoct_out.11.contigs__.RAST 0.1 4269\n",
      "Salt_Pond_MetaG_R2_restored_C_black_MG_DASTool_bins_metabat.8.contigs__.RAST 0.1 10597\n",
      "Salt_Pond_MetaG_R2_restored_H2O_MG_DASTool_bins_maxbin.002.contigs__.RAST 0.1 1469\n",
      "Salt_Pond_MetaG_R2_A_D1_MG_DASTool_bins_concoct_out.119.contigs__.RAST 0.1 1908\n",
      "Salt_Pond_MetaG_R2_B_D2_MG_DASTool_bins_concoct_out.39.contigs__.RAST 0.1 7301\n",
      "Salt_Pond_MetaG_R1_B_H2O_MG_DASTool_bins_metabat.17.contigs__.RAST 0.1 1611\n",
      "Salt_Pond_MetaG_R2_C_D2_MG_DASTool_bins_concoct_out.47.contigs__.RAST 0.1 4654\n",
      "Salt_Pond_MetaG_R2_restored_DShore_MG_DASTool_bins_concoct_out.21.contigs__.RAST 0.1 11100\n",
      "Salt_Pond_MetaG_R2A_C_D1_MG_DASTool_bins_metabat.5.contigs__.RAST 0.1 6377\n",
      "Salt_Pond_MetaG_R2A_A_H2O_MG_DASTool_bins_concoct_out.78.contigs__.RAST 0.1 8338\n",
      "Salt_Pond_MetaGSF2_B_H2O_MG_DASTool_bins_metabat.39.contigs__.RAST 0.1 1096\n",
      "Salt_Pond_MetaG_R2A_B_H2O_MG_DASTool_bins_maxbin.029.contigs__.RAST 0.1 3647\n",
      "Salt_Pond_MetaGSF2_A_H2O_MG_DASTool_bins_metabat.23.contigs__.RAST 0.1 887\n",
      "Salt_Pond_MetaG_R2A_C_D2_MG_DASTool_bins_concoct_out.45.contigs__.RAST 0.1 7845\n",
      "Salt_Pond_MetaG_R2A_C_H2O_MG_DASTool_bins_metabat.5.contigs__.RAST 0.1 556\n",
      "Salt_Pond_MetaGSF2_C_H2O_MG_DASTool_bins_metabat.29.contigs__.RAST 0.1 1097\n",
      "Salt_Pond_MetaG_R1_A_D2_MG_DASTool_bins_metabat.27.contigs__.RAST 0.1 2113\n",
      "Salt_Pond_MetaG_R1_C_D2_MG_DASTool_bins_metabat.40.contigs__.RAST 0.1 3981\n",
      "Salt_Pond_MetaG_R1_B_D1_MG_DASTool_bins_concoct_out.53.contigs__.RAST 0.1 2440\n",
      "Salt_Pond_MetaG_R2_A_H2O_MG_DASTool_bins_metabat.14.contigs__.RAST 0.1 4191\n",
      "Salt_Pond_MetaG_R2_C_D1_MG_DASTool_bins_concoct_out.65.contigs__.RAST 0.1 9238\n",
      "Salt_Pond_MetaG_R2_B_H2O_MG_DASTool_bins_metabat.29.contigs__.RAST 0.1 591\n",
      "Salt_Pond_MetaG_R2_restored_DShore_MG_DASTool_bins_metabat.11.contigs__.RAST 0.1 2988\n",
      "Salt_Pond_MetaG_R1_A_D1_MG_DASTool_bins.metabat.18.contigs__.RAST 0.1 3452\n",
      "Salt_Pond_MetaG_R2_C_H2O_MG_DASTool_bins_metabat.29.contigs__.RAST 0.1 352\n",
      "Salt_Pond_MetaG_R1_C_H2O_MG_DASTool_bins_concoct_out.16.contigs__.RAST 0.1 571\n",
      "Salt_Pond_MetaG_R2_C_D1_MG_DASTool_bins_maxbin.062.contigs__.RAST 0.1 6108\n",
      "Salt_Pond_MetaG_R2A_C_D2_MG_DASTool_bins_concoct_out.10.contigs__.RAST 0.1 10540\n",
      "Salt_Pond_MetaGSF2_A_D2_MG_DASTool_bins_concoct_out.11.contigs__.RAST 0.1 2899\n",
      "Salt_Pond_MetaG_R1_A_D1_MG_DASTool_bins.concoct_out.54.contigs__.RAST 0.1 7022\n",
      "Salt_Pond_MetaG_R2A_A_D1_MG_DASTool_bins_concoct_out.50.contigs__.RAST 0.1 3801\n",
      "Salt_Pond_MetaGSF2_B_H2O_MG_DASTool_bins_metabat.25.contigs__.RAST 0.1 3131\n",
      "Salt_Pond_MetaGSF2_A_D2_MG_DASTool_bins_concoct_out.40.contigs__.RAST 0.1 1793\n",
      "Salt_Pond_MetaG_R1_A_H2O_MG_DASTool_bins_metabat.8.contigs__.RAST 0.1 4899\n",
      "Salt_Pond_MetaG_R1_B_D1_MG_DASTool_bins_metabat.49.contigs__.RAST 0.1 10297\n",
      "Salt_Pond_MetaG_R2_B_D2_MG_DASTool_bins_metabat.20.contigs__.RAST 0.1 752\n",
      "Salt_Pond_MetaG_R1_B_H2O_MG_DASTool_bins_metabat.5.contigs__.RAST 0.1 4011\n",
      "Salt_Pond_MetaG_R2_C_D1_MG_DASTool_bins_metabat.25.contigs__.RAST 0.1 4998\n",
      "Salt_Pond_MetaG_R2_restored_H2O_MG_DASTool_bins_maxbin.005.contigs__.RAST 0.1 3128\n",
      "Salt_Pond_MetaG_R2_A_D1_MG_DASTool_bins_concoct_out.98.contigs__.RAST 0.1 675\n",
      "Salt_Pond_MetaG_R1_A_D2_MG_DASTool_bins_metabat.45.contigs__.RAST 0.1 9497\n",
      "Salt_Pond_MetaG_R2_restored_C_black_MG_DASTool_bins_metabat.22.contigs__.RAST 0.1 8159\n",
      "Salt_Pond_MetaG_R1_C_D1_MG_DASTool_bins_maxbin.047.contigs__.RAST 0.1 3398\n",
      "Salt_Pond_MetaG_R2_C_H2O_MG_DASTool_bins_concoct_out.60.contigs__.RAST 0.1 3690\n",
      "Salt_Pond_MetaG_R2A_A_H2O_MG_DASTool_bins_metabat.22.contigs__.RAST 0.1 1781\n",
      "Salt_Pond_MetaG_R2A_C_D2_MG_DASTool_bins_maxbin.022.contigs__.RAST 0.1 5485\n",
      "Salt_Pond_MetaGSF2_C_D2_MG_DASTool_bins_concoct_out.24.contigs__.RAST 0.1 1043\n",
      "Salt_Pond_MetaG_R2A_A_D2_MG_DASTool_bins_concoct_out.37.contigs__.RAST 0.1 10735\n",
      "Salt_Pond_MetaGSF2_C_H2O_MG_DASTool_bins_metabat.16.contigs__.RAST 0.1 1230\n",
      "Salt_Pond_MetaG_R2A_C_D2_MG_DASTool_bins_metabat.18.contigs__.RAST 0.1 11145\n",
      "Salt_Pond_MetaG_R1_A_D2_MG_DASTool_bins_concoct_out.109.contigs__.RAST 0.1 9491\n",
      "Salt_Pond_MetaG_R2_B_H2O_MG_DASTool_bins_metabat.16.contigs__.RAST 0.1 4400\n",
      "Salt_Pond_MetaG_R1_B_D2_MG_DASTool_bins_metabat.19.contigs__.RAST 0.1 10178\n",
      "Salt_Pond_MetaG_R1_C_D2_MG_DASTool_bins_metabat.30.contigs__.RAST 0.1 1342\n",
      "Salt_Pond_MetaG_R2_B_D1_MG_DASTool_bins_concoct_out.40.contigs__.RAST 0.1 7966\n",
      "Salt_Pond_MetaG_R2_C_H2O_MG_DASTool_bins_metabat.20.contigs__.RAST 0.1 4850\n",
      "Salt_Pond_MetaG_R1_B_D1_MG_DASTool_bins_concoct_out.59.contigs__.RAST 0.1 9419\n",
      "Salt_Pond_MetaG_R2_B_D2_MG_DASTool_bins_metabat.43.contigs__.RAST 0.1 11786\n",
      "Salt_Pond_MetaG_R1_C_D2_MG_DASTool_bins_metabat.58.contigs__.RAST 0.1 250\n",
      "Salt_Pond_MetaG_R2A_A_D1_MG_DASTool_bins_metabat.17.contigs__.RAST 0.1 12216\n",
      "Salt_Pond_MetaG_R1_A_D1_MG_DASTool_bins.concoct_out.9.contigs__.RAST 0.1 5455\n",
      "Salt_Pond_MetaGSF2_A_D2_MG_DASTool_bins_concoct_out.33.contigs__.RAST 0.1 4450\n",
      "Salt_Pond_MetaG_R2A_C_D2_MG_DASTool_bins_concoct_out.34.contigs__.RAST 0.1 1077\n",
      "Salt_Pond_MetaGSF2_B_D2_MG_DASTool_bins_concoct_out.55.contigs__.RAST 0.1 1024\n",
      "Salt_Pond_MetaG_R2A_B_D2_MG_DASTool_bins_concoct_out.11.contigs__.RAST 0.1 1395\n",
      "Salt_Pond_MetaGSF2_A_D2_MG_DASTool_bins_concoct_out.28.contigs__.RAST 0.1 9227\n",
      "Salt_Pond_MetaG_R1_A_H2O_MG_DASTool_bins_metabat.6.contigs__.RAST 0.1 1645\n",
      "Salt_Pond_MetaG_R2_B_D2_MG_DASTool_bins_metabat.16.contigs__.RAST 0.1 4132\n",
      "Salt_Pond_MetaG_R1_B_H2O_MG_DASTool_bins_maxbin.028.contigs__.RAST 0.1 3787\n",
      "Salt_Pond_MetaG_R2_A_D1_MG_DASTool_bins_concoct_out.49.contigs__.RAST 0.1 4372\n",
      "Salt_Pond_MetaG_R2_A_D2_MG_DASTool_bins_concoct_out.9.contigs__.RAST 0.1 6576\n",
      "Salt_Pond_MetaG_R2_C_D1_MG_DASTool_bins_metabat.7.contigs__.RAST 0.15 8394\n",
      "Salt_Pond_MetaG_R2_restored_C_black_MG_DASTool_bins_metabat.13.contigs__.RAST 0.1 2270\n",
      "Salt_Pond_MetaG_R2_restored_H2O_MG_DASTool_bins_concoct_out.44.contigs__.RAST 0.1 1294\n",
      "Salt_Pond_MetaG_R2_A_D1_MG_DASTool_bins_concoct_out.84.contigs__.RAST 0.1 5422\n",
      "Salt_Pond_MetaG_R1_A_D2_MG_DASTool_bins_metabat.31.contigs__.RAST 0.1 3853\n",
      "Salt_Pond_MetaG_R1_B_D2_MG_DASTool_bins_concoct_out.37.contigs__.RAST 0.1 6045\n",
      "Salt_Pond_MetaG_R2_C_H2O_MG_DASTool_bins_concoct_out.35.contigs__.RAST 0.1 9582\n",
      "Salt_Pond_MetaG_R2A_A_H2O_MG_DASTool_bins_metabat.20.contigs__.RAST 0.1 1421\n",
      "Salt_Pond_MetaGSF2_A_H2O_MG_DASTool_bins_metabat.34.contigs__.RAST 0.1 1723\n",
      "Salt_Pond_MetaG_R2A_C_D2_MG_DASTool_bins_concoct_out.51.contigs__.RAST 0.1 911\n",
      "Salt_Pond_MetaGSF2_C_D2_MG_DASTool_bins_concoct_out.3.contigs__.RAST 0.1 2642\n",
      "Salt_Pond_MetaG_R2A_A_D2_MG_DASTool_bins_concoct_out.25.contigs__.RAST 0.1 2766\n",
      "Salt_Pond_MetaG_R2A_C_D1_MG_DASTool_bins_concoct_out.8.contigs__.RAST 0.15 10535\n",
      "Salt_Pond_MetaG_R2A_C_H2O_MG_DASTool_bins_metabat.4.contigs__.RAST 0.1 1760\n",
      "Salt_Pond_MetaGSF2_B_H2O_MG_DASTool_bins_concoct_out.14.contigs__.RAST 0.1 1393\n",
      "Salt_Pond_MetaGSF2_C_D2_MG_DASTool_bins_metabat.11.contigs__.RAST 0.1 8787\n",
      "Salt_Pond_MetaG_R1_A_D2_MG_DASTool_bins_concoct_out.51.contigs__.RAST 0.1 1970\n",
      "Salt_Pond_MetaG_R1_B_D1_MG_DASTool_bins_metabat.32.contigs__.RAST 0.1 5166\n",
      "Salt_Pond_MetaGSF2_C_D2_MG_DASTool_bins_concoct_out.17.contigs__.RAST 0.1 1544\n",
      "Salt_Pond_MetaG_R1_C_D2_MG_DASTool_bins_concoct_out.85.contigs__.RAST 0.1 1296\n",
      "Salt_Pond_MetaG_R2_B_D2_MG_DASTool_bins_metabat.55.contigs__.RAST 0.1 4325\n",
      "Salt_Pond_MetaG_R2_A_H2O_MG_DASTool_bins_maxbin.035.contigs__.RAST 0.1 311\n",
      "Salt_Pond_MetaG_R1_B_D2_MG_DASTool_bins_metabat.14.contigs__.RAST 0.1 7677\n",
      "Salt_Pond_MetaG_R1_B_D1_MG_DASTool_bins_metabat.29.contigs__.RAST 0.1 4008\n",
      "Salt_Pond_MetaG_R2_restored_C_black_MG_DASTool_bins_concoct_out.17.contigs__.RAST 0.1 9913\n",
      "Salt_Pond_MetaG_R1_C_H2O_MG_DASTool_bins_concoct_out.79.contigs__.RAST 0.1 5133\n",
      "Salt_Pond_MetaG_R2A_B_D2_MG_DASTool_bins_concoct_out.54.contigs__.RAST 0.1 2713\n",
      "Salt_Pond_MetaG_R2A_C_D2_MG_DASTool_bins_concoct_out.21.contigs__.RAST 0.1 12251\n",
      "Salt_Pond_MetaG_R2A_A_D1_MG_DASTool_bins_concoct_out.42.contigs__.RAST 0.1 3277\n",
      "Salt_Pond_MetaG_R1_A_D1_MG_DASTool_bins.concoct_out.5.contigs__.RAST 0.1 3773\n",
      "Salt_Pond_MetaGSF2_A_H2O_MG_DASTool_bins_concoct_out.23.contigs__.RAST 0.1 3415\n",
      "Salt_Pond_MetaGSF2_C_D2_MG_DASTool_bins_concoct_out.13.contigs__.RAST 0.1 2634\n",
      "Salt_Pond_MetaG_R2A_C_D2_MG_DASTool_bins_concoct_out.41.contigs__.RAST 0.1 12087\n",
      "Salt_Pond_MetaG_R2_A_D2_MG_DASTool_bins_metabat.16.contigs__.RAST 0.1 9561\n",
      "Salt_Pond_MetaG_R1_A_H2O_MG_DASTool_bins_concoct_out.2.contigs__.RAST 0.1 1451\n",
      "Salt_Pond_MetaGSF2_C_H2O_MG_DASTool_bins_metabat.49.contigs__.RAST 0.1 4030\n",
      "Salt_Pond_MetaG_R2_restored_DShore_MG_DASTool_bins_metabat.27.contigs__.RAST 0.1 1436\n",
      "Salt_Pond_MetaG_R2_A_D1_MG_DASTool_bins_concoct_out.52.contigs__.RAST 0.1 436\n",
      "Salt_Pond_MetaG_R2_B_D2_MG_DASTool_bins_concoct_out.124.contigs__.RAST 0.1 2107\n",
      "Salt_Pond_MetaG_R1_B_H2O_MG_DASTool_bins_concoct_out.22.contigs__.RAST 0.1 10477\n",
      "Salt_Pond_MetaG_R1_B_D1_MG_DASTool_bins_metabat.41.contigs__.RAST 0.45 19372\n",
      "Salt_Pond_MetaG_R2_C_D2_MG_DASTool_bins_concoct_out.21.contigs__.RAST 0.1 638\n",
      "Salt_Pond_MetaG_R2_restored_DShore_MG_DASTool_bins_concoct_out.38.contigs__.RAST 0.1 5384\n",
      "Salt_Pond_MetaG_R2_A_D1_MG_DASTool_bins_concoct_out.66.contigs__.RAST 0.1 953\n",
      "Salt_Pond_MetaG_R2A_C_D1_MG_DASTool_bins_concoct_out.52.contigs__.RAST 0.1 1832\n",
      "Salt_Pond_MetaG_R2A_C_D2_MG_DASTool_bins_metabat.27.contigs__.RAST 0.1 13032\n",
      "Salt_Pond_MetaGSF2_C_D2_MG_DASTool_bins_metabat.16.contigs__.RAST 0.35 17490\n",
      "Salt_Pond_MetaG_R2A_C_D2_MG_DASTool_bins_metabat.38.contigs__.RAST 0.1 6478\n",
      "Salt_Pond_MetaG_R1_B_D1_MG_DASTool_bins_metabat.28.contigs__.RAST 0.1 1049\n",
      "Salt_Pond_MetaG_R1_A_D2_MG_DASTool_bins_concoct_out.25.contigs__.RAST 0.1 537\n",
      "Salt_Pond_MetaG_R1_A_H2O_MG_DASTool_bins_metabat.14.contigs__.RAST 0.1 1923\n",
      "Salt_Pond_MetaG_R1_B_D2_MG_DASTool_bins_maxbin.014.contigs__.RAST 0.1 2998\n",
      "Salt_Pond_MetaG_R1_C_D2_MG_DASTool_bins_concoct_out.36.contigs__.RAST 0.1 2672\n",
      "Salt_Pond_MetaG_R2_B_D1_MG_DASTool_bins_concoct_out.110.contigs__.RAST 0.1 3013\n",
      "Salt_Pond_MetaG_R1_A_D1_MG_DASTool_bins.metabat.47.contigs__.RAST 0.1 543\n",
      "Salt_Pond_MetaG_R2_A_D1_MG_DASTool_bins_metabat.50.contigs__.RAST 0.1 9147\n",
      "Salt_Pond_MetaG_R2_C_D1_MG_DASTool_bins_metabat.17.contigs__.RAST 0.1 3891\n",
      "Salt_Pond_MetaG_R2A_A_D2_MG_DASTool_bins_concoct_out.10.contigs__.RAST 0.1 10559\n",
      "Salt_Pond_MetaG_R2A_C_D2_MG_DASTool_bins_concoct_out.16.contigs__.RAST 0.1 11613\n",
      "Salt_Pond_MetaG_R2A_A_D1_MG_DASTool_bins_concoct_out.24.contigs__.RAST 0.1 10255\n",
      "Salt_Pond_MetaGSF2_B_D2_MG_DASTool_bins_metabat.4.contigs__.RAST 0.1 3705\n",
      "Salt_Pond_MetaGSF2_A_D2_MG_DASTool_bins_concoct_out.55.contigs__.RAST 0.1 5072\n",
      "Salt_Pond_MetaG_R1_A_D2_MG_DASTool_bins_metabat.84.contigs__.RAST 0.1 2519\n",
      "Salt_Pond_MetaG_R1_B_D2_MG_DASTool_bins_metabat.16.contigs__.RAST 0.1 3782\n",
      "Salt_Pond_MetaGSF2_C_H2O_MG_DASTool_bins_metabat.13.contigs__.RAST 0.1 3338\n",
      "Salt_Pond_MetaG_R2_restored_DShore_MG_DASTool_bins_metabat.18.contigs__.RAST 0.1 869\n",
      "Salt_Pond_MetaG_R2_B_D2_MG_DASTool_bins_metabat.10.contigs__.RAST 0.1 3442\n",
      "Salt_Pond_MetaG_R2_A_D1_MG_DASTool_bins_concoct_out.35.contigs__.RAST 0.1 9349\n",
      "Salt_Pond_MetaG_R1_B_D1_MG_DASTool_bins_metabat.40.contigs__.RAST 0.1 4159\n",
      "Salt_Pond_MetaG_R1_B_H2O_MG_DASTool_bins_concoct_out.19.contigs__.RAST 0.1 637\n",
      "Salt_Pond_MetaG_R2_A_D1_MG_DASTool_bins_metabat.32.contigs__.RAST 0.1 3215\n",
      "Salt_Pond_MetaG_R2_restored_H2O_MG_DASTool_bins_maxbin.017.contigs__.RAST 0.1 4145\n",
      "Salt_Pond_MetaG_R2_A_D1_MG_DASTool_bins_concoct_out.93.contigs__.RAST 0.1 529\n",
      "Salt_Pond_MetaG_R2A_C_D1_MG_DASTool_bins_concoct_out.15.contigs__.RAST 0.1 1175\n",
      "Salt_Pond_MetaG_R2A_C_D2_MG_DASTool_bins_metabat.10.contigs__.RAST 0.1 10805\n",
      "Salt_Pond_MetaG_R2A_A_D2_MG_DASTool_bins_concoct_out.51.contigs__.RAST 0.1 2509\n",
      "Salt_Pond_MetaGSF2_C_D2_MG_DASTool_bins_concoct_out.8.contigs__.RAST 0.1 4095\n"
     ]
    }
   ],
   "source": [
    "%run cliffcommutil.py\n",
    "mag_list = util.load(\"mag_list\")\n",
    "mag_thresholds = util.load(\"mag_thresholds\")\n",
    "#mag_protein_supplements = util.load(\"mag_protein_supplements\")\n",
    "records = []\n",
    "mag_probability_threshold = {}\n",
    "for item in mag_list:\n",
    "    if item[1] in mag_protein_supplements:\n",
    "        count = mag_thresholds[item[1]][\"threshold_count\"]\n",
    "        record = {\"mag\":item[1]}\n",
    "        records.append(record)\n",
    "        abundance_count = [0] * 400\n",
    "        for protein in mag_protein_supplements[item[1]]:\n",
    "            fraction = mag_protein_supplements[item[1]][protein][0]/count\n",
    "            entry = int(fraction*100/5)\n",
    "            abundance_count[entry] += 1\n",
    "        total = 0\n",
    "        final_total = None\n",
    "        mag_probability_threshold[item[1]] = 0.1\n",
    "        for (i,entry) in enumerate(abundance_count):\n",
    "            index = len(abundance_count)-i-1\n",
    "            lasttotal = total\n",
    "            total += abundance_count[index]\n",
    "            if total >= 20000 and final_total == None:\n",
    "                threshold = 5*(index+1)/100\n",
    "                if threshold >= 0.1:\n",
    "                    mag_probability_threshold[item[1]] = threshold\n",
    "                    final_total = lasttotal\n",
    "            if index == 2 and final_total == None:\n",
    "                final_total = total\n",
    "        print(item[1],mag_probability_threshold[item[1]],final_total)\n",
    "        for (i,entry) in enumerate(abundance_count):\n",
    "            record[i] = entry\n",
    "util.save(\"mag_probability_threshold\",mag_probability_threshold)\n",
    "df = pd.DataFrame.from_records(records)\n",
    "df.to_csv(util.output_dir+\"/protein_count_abundance.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Renaming MAGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output files printed to:/Users/chenry/code/notebooks/MicrobiomeNotebooks/Cliff/nboutput when using KBDevUtils.output_dir\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1722057900.422139 ERROR: Requested data mag_list doesn't exist at /Users/chenry/code/notebooks/MicrobiomeNotebooks/Cliff/datacache/mag_list.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelSEED: /Users/chenry/code//kb_sdk/run_local/workdir/tmp/\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Requested data mag_list doesn't exist at /Users/chenry/code/notebooks/MicrobiomeNotebooks/Cliff/datacache/mag_list.json",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m mag_to_name \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m      3\u001b[0m name_to_mag \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m----> 4\u001b[0m mag_list \u001b[38;5;241m=\u001b[39m \u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmag_list\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mag \u001b[38;5;129;01min\u001b[39;00m mag_list:\n\u001b[1;32m      6\u001b[0m     original_name \u001b[38;5;241m=\u001b[39m mag[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/code//chenry_utility_module/lib/chenry_utility_module/kbdevutils.py:147\u001b[0m, in \u001b[0;36mKBDevUtils.load\u001b[0;34m(self, name, default)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m default \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    146\u001b[0m         logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRequested data \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mname\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt exist at \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mfilename)\n\u001b[0;32m--> 147\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m(\u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRequested data \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mname\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt exist at \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mfilename))\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m default\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[0;31mValueError\u001b[0m: Requested data mag_list doesn't exist at /Users/chenry/code/notebooks/MicrobiomeNotebooks/Cliff/datacache/mag_list.json"
     ]
    }
   ],
   "source": [
    "%run cliffcommutil.py\n",
    "mag_to_name = {}\n",
    "name_to_mag = {}\n",
    "mag_list = util.load(\"mag_list\")\n",
    "for mag in mag_list:\n",
    "    original_name = mag[1]\n",
    "    new_name = original_name\n",
    "    new_name = new_name.replace(\"Salt_Pond_MetaG_\", \"\", 1)\n",
    "    new_name = new_name.replace(\"Salt_Pond_MetaG\", \"\", 1)\n",
    "    new_name = new_name.replace(\"_MG_DASTool_bins_\", \"\", 1)\n",
    "    new_name = new_name.replace(\"metabat\", \"\", 1)\n",
    "    new_name = new_name.replace(\"concoct_out\", \"\", 1)\n",
    "    new_name = new_name.replace(\"maxbin\", \"\", 1)\n",
    "    new_name = new_name.replace(\".contigs__.RAST\", \"\", 1)\n",
    "    mag_to_name[mag[1]] = new_name\n",
    "    name_to_mag[new_name] = mag[1]\n",
    "    print(name_to_mag)\n",
    "util.save(\"mag_to_name\",mag_to_name)\n",
    "util.save(\"name_to_mag\",name_to_mag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading protein sequence data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output files printed to:/scratch/chenry/MicrobiomeNotebooks/Cliff/nboutput when using KBDevUtils.output_dir\n",
      "ModelSEED: /scratch/shared//sdkmount/kb_sdk_home/run_local/workdir/tmp/\n"
     ]
    }
   ],
   "source": [
    "%run cliffcommutil.py\n",
    "from Bio import SeqIO\n",
    "protein_hash = {}\n",
    "for record in SeqIO.parse('/scratch/fliu/data/cliff/mmseqs_ani_prob_rep_genome_v2.faa', 'fasta'):\n",
    "    protein_hash[record.id] = record.seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Building genomes and assemblies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output files printed to:/scratch/chenry/MicrobiomeNotebooks/Cliff/nboutput when using KBDevUtils.output_dir\n",
      "ModelSEED: /scratch/shared//sdkmount/kb_sdk_home/run_local/workdir/tmp/\n",
      "Salt_Pond_MetaGSF2_B_H2O_MG_DASTool_bins_metabat.8.contigs__.RAST 14738\n",
      "Salt_Pond_MetaG_R1_B_D1_MG_DASTool_bins_metabat.20.contigs__.RAST 3861\n",
      "Salt_Pond_MetaG_R2_B_D2_MG_DASTool_bins_concoct_out.4.contigs__.RAST 4005\n",
      "Salt_Pond_MetaG_R2_restored_DShore_MG_DASTool_bins_concoct_out.46.contigs__.RAST 4005\n",
      "Salt_Pond_MetaG_R1_A_D2_MG_DASTool_bins_concoct_out.21.contigs__.RAST 4193\n",
      "Salt_Pond_MetaG_R1_C_D1_MG_DASTool_bins_metabat.31.contigs__.RAST 5107\n",
      "Salt_Pond_MetaG_R2_A_H2O_MG_DASTool_bins_concoct_out.29.contigs__.RAST 3671\n",
      "Salt_Pond_MetaG_R2_B_D2_MG_DASTool_bins_metabat.50.contigs__.RAST 4272\n",
      "Salt_Pond_MetaG_R1_B_D2_MG_DASTool_bins_metabat.18.contigs__.RAST 4145\n",
      "Salt_Pond_MetaGSF2_C_D2_MG_DASTool_bins_concoct_out.32.contigs__.RAST 4145\n",
      "Salt_Pond_MetaG_R1_A_D1_MG_DASTool_bins.metabat.15.contigs__.RAST 1458\n",
      "Salt_Pond_MetaG_R2_C_D1_MG_DASTool_bins_concoct_out.88.contigs__.RAST 2331\n",
      "Salt_Pond_MetaG_R2_restored_C_black_MG_DASTool_bins_concoct_out.57.contigs__.RAST 1739\n",
      "Salt_Pond_MetaG_R2_A_D1_MG_DASTool_bins_metabat.10.contigs__.RAST 2714\n",
      "Salt_Pond_MetaGSF2_B_D1_MG_DASTool_bins_concoct_out.44.contigs__.RAST 3228\n",
      "Salt_Pond_MetaG_R2A_A_D1_MG_DASTool_bins_concoct_out.51.contigs__.RAST 1179\n",
      "Salt_Pond_MetaG_R2A_B_H2O_MG_DASTool_bins_concoct_out.69.contigs__.RAST 1708\n",
      "Salt_Pond_MetaG_R2A_C_H2O_MG_DASTool_bins_metabat.16.contigs__.RAST 553\n",
      "Salt_Pond_MetaG_R2A_C_D1_MG_DASTool_bins_metabat.18.contigs__.RAST 1602\n",
      "Salt_Pond_MetaG_R2A_B_H2O_MG_DASTool_bins_metabat.10.contigs__.RAST 527\n",
      "Salt_Pond_MetaGSF2_C_D2_MG_DASTool_bins_concoct_out.25.contigs__.RAST 4055\n",
      "Salt_Pond_MetaG_R1_B_D2_MG_DASTool_bins_concoct_out.86.contigs__.RAST 4055\n",
      "Salt_Pond_MetaG_R2_A_D2_MG_DASTool_bins_concoct_out.67.contigs__.RAST 4080\n",
      "Salt_Pond_MetaG_R2_restored_DShore_MG_DASTool_bins_metabat.25.contigs__.RAST 1643\n",
      "Salt_Pond_MetaG_R1_A_D2_MG_DASTool_bins_metabat.50.contigs__.RAST 3744\n",
      "Salt_Pond_MetaG_R2_restored_C_black_MG_DASTool_bins_metabat.2.contigs__.RAST 3744\n",
      "Salt_Pond_MetaG_R2_A_D1_MG_DASTool_bins_concoct_out.29.contigs__.RAST 2512\n",
      "Salt_Pond_MetaG_R1_B_D1_MG_DASTool_bins_metabat.38.contigs__.RAST 7765\n",
      "Salt_Pond_MetaG_R2_B_D2_MG_DASTool_bins_concoct_out.80.contigs__.RAST 1131\n",
      "Salt_Pond_MetaG_R1_B_H2O_MG_DASTool_bins_concoct_out.13.contigs__.RAST 1059\n",
      "Salt_Pond_MetaG_R2_C_D2_MG_DASTool_bins_concoct_out.45.contigs__.RAST 4869\n",
      "Salt_Pond_MetaG_R2_restored_DShore_MG_DASTool_bins_concoct_out.17.contigs__.RAST 12880\n",
      "Salt_Pond_MetaG_R2A_C_D1_MG_DASTool_bins_metabat.4.contigs__.RAST 11688\n",
      "Salt_Pond_MetaGSF2_B_H2O_MG_DASTool_bins_metabat.28.contigs__.RAST 2668\n",
      "Salt_Pond_MetaG_R2A_A_H2O_MG_DASTool_bins_concoct_out.62.contigs__.RAST 3463\n",
      "Salt_Pond_MetaG_R2A_C_D2_MG_DASTool_bins_concoct_out.42.contigs__.RAST 3491\n",
      "Salt_Pond_MetaGSF2_A_H2O_MG_DASTool_bins_metabat.14.contigs__.RAST 12247\n",
      "Salt_Pond_MetaG_R2A_C_D1_MG_DASTool_bins_metabat.17.contigs__.RAST 2857\n",
      "Salt_Pond_MetaGSF2_B_H2O_MG_DASTool_bins_concoct_out.91.contigs__.RAST 1995\n",
      "Salt_Pond_MetaG_R2_B_D1_MG_DASTool_bins_metabat.22.contigs__.RAST 12203\n",
      "Salt_Pond_MetaG_R1_B_D2_MG_DASTool_bins_metabat.34.contigs__.RAST 6052\n",
      "Salt_Pond_MetaGSF2_C_D2_MG_DASTool_bins_metabat.19.contigs__.RAST 17764\n",
      "Salt_Pond_MetaG_R2_restored_DShore_MG_DASTool_bins_concoct_out.37.contigs__.RAST 13721\n",
      "Salt_Pond_MetaG_R1_A_D2_MG_DASTool_bins_concoct_out.1.contigs__.RAST 771\n",
      "Salt_Pond_MetaG_R1_B_D1_MG_DASTool_bins_metabat.16.contigs__.RAST 7788\n",
      "Salt_Pond_MetaG_R2_B_D2_MG_DASTool_bins_metabat.52.contigs__.RAST 4104\n",
      "Salt_Pond_MetaG_R1_B_D2_MG_DASTool_bins_concoct_out.120.contigs__.RAST 4531\n",
      "Salt_Pond_MetaG_R2A_C_D2_MG_DASTool_bins_concoct_out.34.contigs__.RAST 1078\n",
      "Salt_Pond_MetaGSF2_B_D2_MG_DASTool_bins_concoct_out.55.contigs__.RAST 1025\n",
      "Salt_Pond_MetaG_R2A_B_D2_MG_DASTool_bins_concoct_out.11.contigs__.RAST 1396\n",
      "Salt_Pond_MetaGSF2_A_D2_MG_DASTool_bins_concoct_out.28.contigs__.RAST 9228\n",
      "Salt_Pond_MetaG_R1_A_H2O_MG_DASTool_bins_metabat.6.contigs__.RAST 1646\n",
      "Salt_Pond_MetaG_R2_B_D2_MG_DASTool_bins_metabat.16.contigs__.RAST 4133\n",
      "Salt_Pond_MetaG_R1_B_H2O_MG_DASTool_bins_maxbin.028.contigs__.RAST 3788\n",
      "Salt_Pond_MetaG_R2_A_D1_MG_DASTool_bins_concoct_out.49.contigs__.RAST 4373\n",
      "Salt_Pond_MetaG_R2_A_D2_MG_DASTool_bins_concoct_out.9.contigs__.RAST 6577\n",
      "Salt_Pond_MetaG_R2_C_D1_MG_DASTool_bins_metabat.7.contigs__.RAST 8395\n",
      "Salt_Pond_MetaG_R2_restored_C_black_MG_DASTool_bins_metabat.13.contigs__.RAST 2271\n",
      "Salt_Pond_MetaG_R2_restored_H2O_MG_DASTool_bins_concoct_out.44.contigs__.RAST 1295\n",
      "Salt_Pond_MetaG_R2_A_D1_MG_DASTool_bins_concoct_out.84.contigs__.RAST 5423\n",
      "Salt_Pond_MetaG_R1_A_D2_MG_DASTool_bins_metabat.31.contigs__.RAST 3854\n",
      "Salt_Pond_MetaG_R1_B_D2_MG_DASTool_bins_concoct_out.37.contigs__.RAST 6046\n",
      "Salt_Pond_MetaG_R2_C_H2O_MG_DASTool_bins_concoct_out.35.contigs__.RAST 9583\n",
      "Salt_Pond_MetaG_R2A_A_H2O_MG_DASTool_bins_metabat.20.contigs__.RAST 1422\n",
      "Salt_Pond_MetaGSF2_A_H2O_MG_DASTool_bins_metabat.34.contigs__.RAST 1724\n",
      "Salt_Pond_MetaG_R2A_C_D2_MG_DASTool_bins_concoct_out.51.contigs__.RAST 912\n",
      "Salt_Pond_MetaGSF2_C_D2_MG_DASTool_bins_concoct_out.3.contigs__.RAST 2643\n",
      "Salt_Pond_MetaG_R2A_A_D2_MG_DASTool_bins_concoct_out.25.contigs__.RAST 2767\n",
      "Salt_Pond_MetaG_R2A_C_D1_MG_DASTool_bins_concoct_out.8.contigs__.RAST 10536\n",
      "Salt_Pond_MetaG_R2A_C_D1_MG_DASTool_bins_metabat.16.contigs__.RAST 10536\n",
      "Salt_Pond_MetaG_R2A_C_H2O_MG_DASTool_bins_metabat.4.contigs__.RAST 1761\n",
      "Salt_Pond_MetaGSF2_B_H2O_MG_DASTool_bins_concoct_out.14.contigs__.RAST 1394\n",
      "Salt_Pond_MetaGSF2_C_D2_MG_DASTool_bins_metabat.11.contigs__.RAST 8788\n",
      "Salt_Pond_MetaG_R1_A_D2_MG_DASTool_bins_concoct_out.51.contigs__.RAST 1971\n",
      "Salt_Pond_MetaG_R1_B_D1_MG_DASTool_bins_metabat.32.contigs__.RAST 5167\n",
      "Salt_Pond_MetaGSF2_C_D2_MG_DASTool_bins_concoct_out.17.contigs__.RAST 1545\n",
      "Salt_Pond_MetaG_R1_C_D2_MG_DASTool_bins_concoct_out.85.contigs__.RAST 1297\n",
      "Salt_Pond_MetaG_R2_restored_DShore_MG_DASTool_bins_concoct_out.20.contigs__.RAST 1297\n",
      "Salt_Pond_MetaG_R2_B_D2_MG_DASTool_bins_metabat.55.contigs__.RAST 4326\n",
      "Salt_Pond_MetaG_R2_A_H2O_MG_DASTool_bins_maxbin.035.contigs__.RAST 312\n",
      "Salt_Pond_MetaG_R1_B_D2_MG_DASTool_bins_metabat.14.contigs__.RAST 7678\n",
      "Salt_Pond_MetaG_R2_C_D1_MG_DASTool_bins_concoct_out.37.contigs__.RAST 7678\n",
      "Salt_Pond_MetaG_R1_B_D1_MG_DASTool_bins_metabat.29.contigs__.RAST 4009\n",
      "Salt_Pond_MetaG_R2_restored_C_black_MG_DASTool_bins_concoct_out.17.contigs__.RAST 9914\n",
      "Salt_Pond_MetaG_R2_restored_DShore_MG_DASTool_bins_metabat.8.contigs__.RAST 9914\n",
      "Salt_Pond_MetaG_R1_C_H2O_MG_DASTool_bins_concoct_out.79.contigs__.RAST 5134\n",
      "Salt_Pond_MetaG_R2A_B_D2_MG_DASTool_bins_concoct_out.54.contigs__.RAST 2714\n",
      "Salt_Pond_MetaG_R2A_C_D2_MG_DASTool_bins_concoct_out.21.contigs__.RAST 12252\n",
      "Salt_Pond_MetaG_R2A_A_D1_MG_DASTool_bins_concoct_out.42.contigs__.RAST 3278\n",
      "Salt_Pond_MetaG_R1_A_D1_MG_DASTool_bins.concoct_out.5.contigs__.RAST 3774\n",
      "Salt_Pond_MetaGSF2_A_H2O_MG_DASTool_bins_concoct_out.23.contigs__.RAST 3416\n",
      "Salt_Pond_MetaGSF2_C_D2_MG_DASTool_bins_concoct_out.13.contigs__.RAST 2635\n",
      "Salt_Pond_MetaG_R2A_C_D2_MG_DASTool_bins_concoct_out.41.contigs__.RAST 12088\n",
      "Salt_Pond_MetaG_R2_A_D2_MG_DASTool_bins_metabat.16.contigs__.RAST 9562\n",
      "Salt_Pond_MetaG_R1_A_H2O_MG_DASTool_bins_concoct_out.2.contigs__.RAST 1452\n",
      "Salt_Pond_MetaGSF2_C_H2O_MG_DASTool_bins_metabat.49.contigs__.RAST 4031\n",
      "Salt_Pond_MetaG_R2_restored_DShore_MG_DASTool_bins_metabat.27.contigs__.RAST 1437\n",
      "Salt_Pond_MetaG_R2_A_D1_MG_DASTool_bins_concoct_out.52.contigs__.RAST 437\n",
      "Salt_Pond_MetaG_R2_A_D1_MG_DASTool_bins_metabat.24.contigs__.RAST 437\n",
      "Salt_Pond_MetaG_R2_B_D2_MG_DASTool_bins_concoct_out.124.contigs__.RAST 2108\n",
      "Salt_Pond_MetaG_R1_B_H2O_MG_DASTool_bins_concoct_out.22.contigs__.RAST 10478\n",
      "Salt_Pond_MetaG_R1_B_D1_MG_DASTool_bins_metabat.41.contigs__.RAST 19373\n",
      "Salt_Pond_MetaG_R2_C_D2_MG_DASTool_bins_concoct_out.21.contigs__.RAST 639\n",
      "Salt_Pond_MetaG_R2_restored_DShore_MG_DASTool_bins_concoct_out.38.contigs__.RAST 5385\n",
      "Salt_Pond_MetaG_R2A_A_D1_MG_DASTool_bins_concoct_out.6.contigs__.RAST 5385\n",
      "Salt_Pond_MetaG_R2_A_D1_MG_DASTool_bins_concoct_out.66.contigs__.RAST 954\n",
      "Salt_Pond_MetaG_R2A_C_D1_MG_DASTool_bins_concoct_out.52.contigs__.RAST 1833\n",
      "Salt_Pond_MetaG_R2A_C_D2_MG_DASTool_bins_metabat.27.contigs__.RAST 13033\n",
      "Salt_Pond_MetaG_R2A_A_D2_MG_DASTool_bins_metabat.7.contigs__.RAST 13033\n",
      "Salt_Pond_MetaGSF2_C_D2_MG_DASTool_bins_metabat.16.contigs__.RAST 17491\n",
      "Salt_Pond_MetaG_R2A_C_D2_MG_DASTool_bins_metabat.38.contigs__.RAST 6479\n",
      "Salt_Pond_MetaG_R1_B_D1_MG_DASTool_bins_metabat.28.contigs__.RAST 1050\n",
      "Salt_Pond_MetaG_R1_A_D2_MG_DASTool_bins_concoct_out.25.contigs__.RAST 538\n",
      "Salt_Pond_MetaG_R2_B_D2_MG_DASTool_bins_metabat.62.contigs__.RAST 538\n",
      "Salt_Pond_MetaG_R1_A_H2O_MG_DASTool_bins_metabat.14.contigs__.RAST 1924\n",
      "Salt_Pond_MetaG_R1_B_D2_MG_DASTool_bins_maxbin.014.contigs__.RAST 2999\n",
      "Salt_Pond_MetaG_R1_C_D2_MG_DASTool_bins_concoct_out.36.contigs__.RAST 2673\n",
      "Salt_Pond_MetaG_R2_B_D1_MG_DASTool_bins_concoct_out.110.contigs__.RAST 3014\n",
      "Salt_Pond_MetaG_R2_C_D1_MG_DASTool_bins_concoct_out.7.contigs__.RAST 3014\n",
      "Salt_Pond_MetaG_R2_restored_C_black_MG_DASTool_bins_concoct_out.12.contigs__.RAST 3014\n",
      "Salt_Pond_MetaG_R1_A_D1_MG_DASTool_bins.metabat.47.contigs__.RAST 544\n",
      "Salt_Pond_MetaG_R2_restored_DShore_MG_DASTool_bins_maxbin.037.contigs__.RAST 544\n",
      "Salt_Pond_MetaG_R2_A_D1_MG_DASTool_bins_metabat.50.contigs__.RAST 9148\n",
      "Salt_Pond_MetaG_R2_C_D1_MG_DASTool_bins_metabat.17.contigs__.RAST 3892\n",
      "Salt_Pond_MetaG_R2A_A_D2_MG_DASTool_bins_concoct_out.10.contigs__.RAST 10560\n",
      "Salt_Pond_MetaG_R2A_B_D2_MG_DASTool_bins_concoct_out.47.contigs__.RAST 10560\n",
      "Salt_Pond_MetaG_R2A_C_D2_MG_DASTool_bins_concoct_out.16.contigs__.RAST 11614\n",
      "Salt_Pond_MetaG_R2A_A_D1_MG_DASTool_bins_concoct_out.24.contigs__.RAST 10256\n",
      "Salt_Pond_MetaGSF2_B_D2_MG_DASTool_bins_metabat.4.contigs__.RAST 3706\n",
      "Salt_Pond_MetaGSF2_A_D2_MG_DASTool_bins_concoct_out.55.contigs__.RAST 5073\n",
      "Salt_Pond_MetaG_R2A_C_D2_MG_DASTool_bins_concoct_out.36.contigs__.RAST 5073\n",
      "Salt_Pond_MetaG_R1_A_D2_MG_DASTool_bins_metabat.84.contigs__.RAST 2520\n",
      "Salt_Pond_MetaG_R1_B_D2_MG_DASTool_bins_metabat.16.contigs__.RAST 3783\n",
      "Salt_Pond_MetaGSF2_C_H2O_MG_DASTool_bins_metabat.13.contigs__.RAST 3339\n",
      "Salt_Pond_MetaG_R2_restored_DShore_MG_DASTool_bins_metabat.18.contigs__.RAST 870\n",
      "Salt_Pond_MetaG_R2_B_D2_MG_DASTool_bins_metabat.10.contigs__.RAST 3443\n",
      "Salt_Pond_MetaG_R2_A_D1_MG_DASTool_bins_concoct_out.35.contigs__.RAST 9350\n",
      "Salt_Pond_MetaG_R1_B_D1_MG_DASTool_bins_metabat.40.contigs__.RAST 4160\n",
      "Salt_Pond_MetaG_R1_B_H2O_MG_DASTool_bins_concoct_out.19.contigs__.RAST 638\n",
      "Salt_Pond_MetaG_R2_A_D1_MG_DASTool_bins_metabat.32.contigs__.RAST 3216\n",
      "Salt_Pond_MetaG_R2_C_D2_MG_DASTool_bins_concoct_out.104.contigs__.RAST 3216\n",
      "Salt_Pond_MetaG_R2_restored_DShore_MG_DASTool_bins_concoct_out.12.contigs__.RAST 3216\n",
      "Salt_Pond_MetaG_R2_restored_H2O_MG_DASTool_bins_maxbin.017.contigs__.RAST 4146\n",
      "Salt_Pond_MetaG_R2_A_D1_MG_DASTool_bins_concoct_out.93.contigs__.RAST 530\n",
      "Salt_Pond_MetaG_R2A_C_D1_MG_DASTool_bins_concoct_out.15.contigs__.RAST 1176\n",
      "Salt_Pond_MetaG_R2A_C_D2_MG_DASTool_bins_metabat.10.contigs__.RAST 10806\n",
      "Salt_Pond_MetaG_R2A_A_D2_MG_DASTool_bins_concoct_out.51.contigs__.RAST 2510\n",
      "Salt_Pond_MetaGSF2_C_D2_MG_DASTool_bins_concoct_out.8.contigs__.RAST 4096\n"
     ]
    }
   ],
   "source": [
    "%run cliffcommutil.py\n",
    "unfiltered_list = util.load(\"mag_list\")\n",
    "filter = [\n",
    "  \"Salt_Pond_MetaG_R2_restored_C_black_MG_DASTool_bins_concoct_out.17.contigs__.RAST\",\n",
    "  \"Salt_Pond_MetaG_R2_A_D1_MG_DASTool_bins_concoct_out.52.contigs__.RAST\",\n",
    "  \"Salt_Pond_MetaG_R2_restored_DShore_MG_DASTool_bins_concoct_out.38.contigs__.RAST\",\n",
    "  \"Salt_Pond_MetaG_R2A_C_D2_MG_DASTool_bins_metabat.27.contigs__.RAST\",\n",
    "  \"Salt_Pond_MetaG_R1_A_D2_MG_DASTool_bins_concoct_out.25.contigs__.RAST\",\n",
    "  \"Salt_Pond_MetaG_R2_B_D1_MG_DASTool_bins_concoct_out.110.contigs__.RAST\",\n",
    "  \"Salt_Pond_MetaG_R1_A_D1_MG_DASTool_bins.metabat.47.contigs__.RAST\",\n",
    "  \"Salt_Pond_MetaG_R2A_A_D2_MG_DASTool_bins_concoct_out.10.contigs__.RAST\",\n",
    "  \"Salt_Pond_MetaGSF2_A_D2_MG_DASTool_bins_concoct_out.55.contigs__.RAST\",\n",
    "  \"Salt_Pond_MetaG_R2_A_D1_MG_DASTool_bins_metabat.32.contigs__.RAST\"\n",
    "]\n",
    "mag_list = []\n",
    "for item in unfiltered_list:\n",
    "    if item[1] in filter or len(filter) == 0:\n",
    "        mag_list.append(item)\n",
    "name_to_mag = util.load(\"name_to_mag\")\n",
    "mag_thresholds = util.load(\"mag_thresholds\")\n",
    "mag_probability_threshold = util.load(\"mag_probability_threshold\")\n",
    "#mag_protein_supplements = util.load(\"mag_protein_supplements\")\n",
    "for item in mag_list:\n",
    "#for name in problem_list:\n",
    "    full_data = util.get_object(item[1],item[7])\n",
    "    genome_obj = full_data[\"data\"]\n",
    "    genome_obj[\"assembly_ref\"] = str(item[6])+\"/\"+str(item[0])+\"/\"+str(item[4])+\";\"+genome_obj[\"assembly_ref\"]\n",
    "    name = mag_to_name[item[1]]\n",
    "    cds_hash = {}\n",
    "    for i,ftr in enumerate(genome_obj[\"cdss\"]):\n",
    "        cds_hash[ftr[\"id\"]] = ftr\n",
    "    ftr_hash = {}\n",
    "    for i,ftr in enumerate(genome_obj[\"features\"]):\n",
    "        ftr_hash[ftr[\"id\"]] = ftr\n",
    "        ftr[\"id\"] = name+\"_\"+str(i+1)\n",
    "        if \"cdss\" in ftr:\n",
    "            for j,cds in enumerate(ftr[\"cdss\"]):\n",
    "                cds_hash[cds][\"id\"] = ftr[\"id\"]+\".CDS\"\n",
    "                ftr[\"cdss\"][j] = cds_hash[cds][\"id\"]\n",
    "                cds_hash[cds][\"parent_gene\"] = ftr[\"id\"]\n",
    "    firstgene = genome_obj[\"features\"][0]\n",
    "    count = 0\n",
    "    if item[1] in mag_protein_supplements:\n",
    "        count = 1\n",
    "        total_genomes = mag_thresholds[item[1]][\"threshold_count\"]\n",
    "        for protein in mag_protein_supplements[item[1]]:\n",
    "            if mag_protein_supplements[item[1]][protein][0]/total_genomes >= mag_probability_threshold[item[1]]:\n",
    "                ftrid = name+'.pg_'+str(count)\n",
    "                count += 1\n",
    "                protseq = str(protein_hash[protein])\n",
    "                dnaseq = util.translate_protein_to_gene(protseq)\n",
    "                result = hashlib.md5(protseq.encode())\n",
    "                md5 = result.hexdigest()\n",
    "                result = hashlib.md5(dnaseq.encode())\n",
    "                dnamd5 = result.hexdigest()\n",
    "                newftr = {\n",
    "                    \"aliases\": [[\"MMseqMD5\",protein]],\n",
    "                    \"cdss\": [\n",
    "                        ftrid+\".CDS\"\n",
    "                    ],\n",
    "                    \"functions\":[\"Hypothetical protein\"],\n",
    "                    \"dna_sequence\": dnaseq,\n",
    "                    \"dna_sequence_length\": 3*len(protseq),\n",
    "                    \"id\": ftrid,\n",
    "                    \"location\": [\n",
    "                        [\n",
    "                            firstgene[\"location\"][0][0],\n",
    "                            1,\n",
    "                            \"+\",\n",
    "                            3*len(protseq)\n",
    "                        ]\n",
    "                    ],\n",
    "                    \"md5\": dnamd5,\n",
    "                    \"ontology_terms\": {},\n",
    "                    \"protein_md5\": md5,\n",
    "                    \"protein_translation\": protseq,\n",
    "                    \"protein_translation_length\": len(protseq),\n",
    "                    \"warnings\": []\n",
    "                }\n",
    "                cdsftr = newftr.copy()\n",
    "                del cdsftr[\"cdss\"]\n",
    "                cdsftr[\"id\"] = ftrid+\".CDS\"\n",
    "                cdsftr[\"parent_gene\"] = ftrid\n",
    "                genome_obj[\"features\"].append(newftr)\n",
    "                genome_obj[\"cdss\"].append(cdsftr)\n",
    "        print(item[1],count)\n",
    "        #Saving MAG\n",
    "        util.save(\"genome/\"+name,full_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding and fixing redundant names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run cliffcommutil.py\n",
    "mag_list = util.load(\"mag_list\")\n",
    "mag_to_name = util.load(\"mag_to_name\")\n",
    "name_to_mag = {}\n",
    "for item in mag_list:\n",
    "    if item[1] not in mag_to_name:\n",
    "        print(\"Missing:\",item[1])\n",
    "    elif mag_to_name[item[1]] in name_to_mag:\n",
    "        print(\"Collision:\",mag_to_name[item[1]])\n",
    "    else:\n",
    "        name_to_mag[mag_to_name[item[1]]] = item[1]\n",
    "util.save(\"name_to_mag\",name_to_mag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading genomes to KBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run cliffcommutil.py\n",
    "unfiltered_list = util.load(\"mag_list\")\n",
    "filter = []\n",
    "mag_list = []\n",
    "for item in unfiltered_list:\n",
    "    if item[1] in filter or len(filter) == 0:\n",
    "        mag_list.append(item)\n",
    "mag_to_name = util.load(\"mag_to_name\")\n",
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "timestamp = datetime.timestamp(now)\n",
    "workspace = 187797\n",
    "anno = util.anno_client()\n",
    "anno.clients[\"GenomeFileUtil\"] = util.gfu_client()\n",
    "finished = util.load(\"finished_genomes\",[])\n",
    "unconverted = {}\n",
    "for item in mag_list:\n",
    "    asvname = mag_to_name[item[1]]\n",
    "    if asvname not in finished:\n",
    "        genome = util.load(\"annotated/\"+asvname)\n",
    "        count = 0\n",
    "        for ftr in genome[\"features\"]:\n",
    "            end = len(asvname)+3\n",
    "            if ftr[\"id\"][0:4] == \"Salt\":\n",
    "                unconverted[item[1]] = 1\n",
    "            if ftr[\"id\"][0:end] == asvname+\".pg\":\n",
    "                count += 1\n",
    "        print(asvname,count)\n",
    "        util.save_ws_object(asvname+\".pg\",187797,genome,\"KBaseGenomes.Genome\")\n",
    "        finished.append(asvname)\n",
    "        util.save(\"finished_genomes\",finished)\n",
    "for item in unconverted:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspecting genomes before load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run cliffcommutil.py\n",
    "mags = util.msrecon.kbase_api.list_objects(187875, object_type=\"KBaseGenomes.Genome\", include_metadata=False)\n",
    "mag_hash = {}\n",
    "for item in mags:\n",
    "    mag_hash[item[1]] = item\n",
    "mag_list = util.load(\"mag_list\")\n",
    "mag_to_name = util.load(\"mag_to_name\")\n",
    "for item in mag_list:\n",
    "    name = mag_to_name[item[1]]\n",
    "    name += \".pangenome.GLM4EC\"\n",
    "    if name in mag_hash:\n",
    "        print(\"Getting \"+name)\n",
    "        full_data = util.get_object(name,187875)\n",
    "        genome = full_data[\"data\"]\n",
    "        ftrhash = {}\n",
    "        for ftr in genome[\"features\"]:\n",
    "            ftrhash[ftr[\"id\"]] = ftr\n",
    "        for ftr in genome[\"cdss\"]:\n",
    "            ftrhash[ftr[\"id\"]] = ftr\n",
    "            if \"parent_gene\" in ftr:\n",
    "                if ftr[\"parent_gene\"] not in ftrhash:\n",
    "                    print(item[1],new_name,\"Gene \"+ftr[\"parent_gene\"]+\" not found!\")\n",
    "        for ftr in genome[\"features\"]:\n",
    "            if \"cdss\" in ftr:\n",
    "                for cds in ftr[\"cdss\"]:\n",
    "                    if cds not in ftrhash:\n",
    "                        print(item[1],new_name,\"CDS \"+cds+\" not found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annotating genomes using RAST API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output files printed to:/Users/chenry/code/notebooks/MicrobiomeNotebooks/Cliff/nboutput when using KBDevUtils.output_dir\n",
      "ModelSEED: /Users/chenry/code//kb_sdk/run_local/workdir/tmp/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1722232442.262796 ERROR: Requested data genome/R1_B_D1.20 doesn't exist at /Users/chenry/code/notebooks/MicrobiomeNotebooks/Cliff/datacache/genome/R1_B_D1.20.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Requested data genome/R1_B_D1.20 doesn't exist at /Users/chenry/code/notebooks/MicrobiomeNotebooks/Cliff/datacache/genome/R1_B_D1.20.json",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 18\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m output:\n\u001b[1;32m     10\u001b[0m     rast_genome \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     11\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m:item[\u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenetic_code\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;241m11\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m\"\u001b[39m:[]\n\u001b[1;32m     17\u001b[0m     }\n\u001b[0;32m---> 18\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgenome/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m     genome \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ftr \u001b[38;5;129;01min\u001b[39;00m genome[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/code//chenry_utility_module/lib/chenry_utility_module/kbdevutils.py:147\u001b[0m, in \u001b[0;36mKBDevUtils.load\u001b[0;34m(self, name, default)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m default \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    146\u001b[0m         logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRequested data \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mname\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt exist at \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mfilename)\n\u001b[0;32m--> 147\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m(\u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRequested data \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mname\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt exist at \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mfilename))\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m default\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[0;31mValueError\u001b[0m: Requested data genome/R1_B_D1.20 doesn't exist at /Users/chenry/code/notebooks/MicrobiomeNotebooks/Cliff/datacache/genome/R1_B_D1.20.json"
     ]
    }
   ],
   "source": [
    "%run cliffcommutil.py\n",
    "mag_list = util.load(\"mag_list\")\n",
    "mag_to_name = util.load(\"mag_to_name\")\n",
    "from modelseedpy.core.rpcclient import RPCClient\n",
    "client = RPCClient(\"https://tutorial.theseed.org/services/genome_annotation\")\n",
    "for item in mag_list:\n",
    "    name = mag_to_name[item[1]]\n",
    "    if name not in output:\n",
    "        rast_genome = {\n",
    "            \"id\":item[1],\n",
    "            \"genetic_code\":11,\n",
    "            \"scientific_name\":\"Unknown\",\n",
    "            \"domain\":\"Bacteria\",\n",
    "            \"contigs\": [],\n",
    "            \"features\":[]\n",
    "        }\n",
    "        data = util.load(\"genome/\"+name)\n",
    "        genome = data[\"data\"]\n",
    "        for ftr in genome[\"features\"]:\n",
    "            rast_genome[\"features\"].append(ftr)\n",
    "        workflow = {\n",
    "            \"stages\":[\n",
    "                {\n",
    "                    \"name\": \"annotate_proteins_kmer_v2\", \n",
    "                    \"kmer_v2_parameters\": {}},\n",
    "                {\n",
    "                    \"name\": \"annotate_proteins_kmer_v1\",\n",
    "                    \"kmer_v1_parameters\": {\"annotate_hypothetical_only\": 1},},\n",
    "                {\n",
    "                    \"name\": \"annotate_proteins_similarity\",\n",
    "                    \"similarity_parameters\": {\"annotate_hypothetical_only\": 1},\n",
    "                },\n",
    "            ]\n",
    "        }\n",
    "        params = [{\"features\": rast_genome[\"features\"]}, workflow]\n",
    "        output = client.call(\"GenomeAnnotation.run_pipeline\",params)\n",
    "        util.save(\"rast/\"+name,output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding RAST ontology event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run cliffcommutil.py\n",
    "mag_list = util.load(\"mag_list\")\n",
    "mag_to_name = util.load(\"mag_to_name\")\n",
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "timestamp = datetime.timestamp(now)\n",
    "for item in mag_list:\n",
    "    name = mag_to_name[item[1]]\n",
    "    data = util.load(\"genome/\"+name)\n",
    "    rast = util.load(\"rast/\"+name)\n",
    "    annoapi = util.anno_client(native_python_api=True)\n",
    "    events = [{\n",
    "        \"ontology_id\" : \"SSO\",\n",
    "        \"description\" : \"RAST Annotation API\",\n",
    "        \"method_version\" : \"1.0\",\n",
    "        \"method\" : \"annotate_genome\",\n",
    "        \"ontology_terms\": {},\n",
    "        \"timestamp\":\"2024-07-29T19:32:45\"\n",
    "    }]\n",
    "    for ftr in rast[0][\"features\"]:\n",
    "        if \"function\" in ftr:\n",
    "            events[0][\"ontology_terms\"][ftr[\"id\"]] = [{\"term\":ftr[\"function\"]}]\n",
    "    output = annoapi.add_annotation_ontology_events({\n",
    "        \"output_workspace\":187797,\n",
    "        \"events\":events,\n",
    "        \"overwrite_matching\":True,\n",
    "        \"object\":data[\"data\"],\n",
    "        \"type\":\"KBaseGenomes.Genome\",\n",
    "        \"input_ref\":None,\n",
    "        \"input_workspace\":None,\n",
    "        \"output_name\":None,\n",
    "        \"save\":0\n",
    "    })\n",
    "    util.save(\"annotated/\"+name,output[\"object\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Printing feature probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run cliffcommutil.py\n",
    "mag_list = util.load(\"mag_list\")\n",
    "mag_thresholds = util.load(\"mag_thresholds\")\n",
    "mag_protein_supplements = util.load(\"mag_protein_supplements\")\n",
    "feature_probabilities = {}\n",
    "for item in mag_list:\n",
    "    data = util.load(\"genome/\"+item[1])\n",
    "    feature_probabilities[item[1]] = {}\n",
    "    ftrs = data[\"data\"][\"features\"]\n",
    "    total_genomes = mag_thresholds[item[1]][\"threshold_count\"]\n",
    "    for ftr in ftrs:\n",
    "        if ftr[\"id\"][0:9] == \"pangenome\":\n",
    "            feature_probabilities[item[1]][ftr[\"id\"]] = mag_protein_supplements[item[1]][ftr[\"aliases\"][0][1]][0]/total_genomes\n",
    "            if feature_probabilities[item[1]][ftr[\"id\"]] > 1:\n",
    "                feature_probabilities[item[1]][ftr[\"id\"]] = 1\n",
    "        else:\n",
    "            feature_probabilities[item[1]][ftr[\"id\"]] = 1\n",
    "util.save(\"feature_probabilities\",feature_probabilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing metabolite data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python version 3.9.19\n",
      "KBBaseModules 0.0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1721792105.8129761 INFO: Note: NumExpr detected 16 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "1721792105.813834 INFO: NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modelseedpy 0.3.3\n",
      "cobrakbase 0.3.1\n",
      "Output files printed to:/Users/chenry/code/notebooks/MicrobiomeNotebooks/Cliff/nboutput when using KBDevUtils.output_dir\n",
      "ModelSEED: /Users/chenry/code//kb_sdk/run_local/workdir/tmp/\n"
     ]
    }
   ],
   "source": [
    "%run cliffcommutil.py\n",
    "metabolite_hash = {\"2'-Deoxyuridine\": 'cpd00412',\n",
    " '2-Oxoglutarate': 'cpd00024',\n",
    " '2-Oxoisocaproate': 'cpd00200',\n",
    " '3-Hydroxybutyrate': 'cpd29193',\n",
    " '3-Hydroxyisovalerate': 'cpd02569',\n",
    " '3-Methyl-2-oxovalerate': 'cpd03737',\n",
    " '4-Aminobutyrate': 'cpd00281',\n",
    " 'Acetate': 'cpd00029',\n",
    " 'Acetone': 'cpd00178',\n",
    " 'Alanine': 'cpd00035',\n",
    " 'Arginine': 'cpd00051',\n",
    " 'Aspartate': 'cpd00041',\n",
    " 'Benzoate': 'cpd00153',\n",
    " 'Betaine': 'cpd00540',\n",
    " 'Dimethylamine': 'cpd00425',\n",
    " 'Ethanol': 'cpd00363',\n",
    " 'Formate': 'cpd00047',\n",
    " 'Fructose': 'cpd01184',\n",
    " 'Fumarate': 'cpd00106',\n",
    " 'Glucose': 'cpd00027',\n",
    " 'Glutamate': 'cpd00023',\n",
    " 'Glycerol': 'cpd00100',\n",
    " 'Isobutyrate': 'cpd01711',\n",
    " 'Isoleucine': 'cpd00322',\n",
    " 'Isopropanol': 'cpd01269',\n",
    " 'Isovalerate': 'cpd05178',\n",
    " 'Lactate': 'cpd00159',\n",
    " 'Leucine': 'cpd00107',\n",
    " 'Maltose': 'cpd00179',\n",
    " 'Methanol': 'cpd00116',\n",
    " 'Methionine': 'cpd00060',\n",
    " 'Methylamine': 'cpd00187',\n",
    " 'Methylguanidine': 'cpd01544',\n",
    " 'N,N-Dimethylglycine': 'cpd00756',\n",
    " 'Phenylacetate': 'cpd19069',\n",
    " 'Phenylalanine': 'cpd00066',\n",
    " 'Proline': 'cpd00129',\n",
    " 'Propionate': 'cpd00141',\n",
    " 'Propylene glycol': 'cpd00453',\n",
    " 'Pyroglutamate': 'cpd01293',\n",
    " 'Succinate': 'cpd00036',\n",
    " 'Sucrose': 'cpd00076',\n",
    " 'Thymidine': 'cpd00184',\n",
    " 'Trehalose': 'cpd00794',\n",
    " 'Trimethylamine': 'cpd00441',\n",
    " 'Tryptophan': 'cpd00065',\n",
    " 'Tyrosine': 'cpd00069',\n",
    " 'Uracil': 'cpd00092',\n",
    " 'Uridine': 'cpd00249',\n",
    " 'Valine': 'cpd00156'}\n",
    "metabolite_names = {}\n",
    "metabolites = []\n",
    "for item in metabolite_hash:\n",
    "    metabolite_names[metabolite_hash[item]] = item\n",
    "    metabolites.append(metabolite_hash[item])\n",
    "util.save(\"metabolite_names\",metabolite_names)\n",
    "util.save(\"metabolites\",metabolites)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing SMIPPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output files printed to:/scratch/chenry/MicrobiomeNotebooks/Cliff/nboutput when using KBDevUtils.output_dir\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1721789912.3593426 ERROR: Requested data metabolites doesn't exist at /scratch/chenry/MicrobiomeNotebooks/Cliff/datacache/metabolites.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelSEED: /scratch/shared//sdkmount/kb_sdk_home/run_local/workdir/tmp/\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Requested data metabolites doesn't exist at /scratch/chenry/MicrobiomeNotebooks/Cliff/datacache/metabolites.json",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m procid \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      3\u001b[0m mag_list \u001b[38;5;241m=\u001b[39m util\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmag_list\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m metabolites \u001b[38;5;241m=\u001b[39m \u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetabolites\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m feature_probabilities \u001b[38;5;241m=\u001b[39m util\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeature_probabilities\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m gf_phenotype_results \u001b[38;5;241m=\u001b[39m util\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnew_gf_phenotype_results_\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(procid),{})\n",
      "File \u001b[0;32m/scratch/shared/code/chenry_utility_module/lib/chenry_utility_module/kbdevutils.py:147\u001b[0m, in \u001b[0;36mKBDevUtils.load\u001b[0;34m(self, name, default)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m default \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    146\u001b[0m         logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRequested data \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mname\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt exist at \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mfilename)\n\u001b[0;32m--> 147\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m(\u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRequested data \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mname\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt exist at \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mfilename))\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m default\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[0;31mValueError\u001b[0m: Requested data metabolites doesn't exist at /scratch/chenry/MicrobiomeNotebooks/Cliff/datacache/metabolites.json"
     ]
    }
   ],
   "source": [
    "%run cliffcommutil.py\n",
    "model_ws = 181152\n",
    "model_suffix = \".mdl\"\n",
    "procid = 0\n",
    "mag_list = util.load(\"mag_list\")\n",
    "metabolites = util.load(\"metabolites\")\n",
    "feature_probabilities = util.load(\"feature_probabilities\")\n",
    "reaction_probabilities = util.load(\"reaction_probabilities\"+str(procid),{})\n",
    "gf_phenotype_results = util.load(\"new_gf_phenotype_results_\"+str(procid),{})\n",
    "probability_finished = util.load(\"probability_finished_\"+str(procid),[])\n",
    "problemlist = util.load(\"problemlist\",[])\n",
    "auxo_media = util.msrecon.get_media(\"181152/AuxoMedia\")\n",
    "gmm_base_media = util.msrecon.get_media(\"181152/BaseAerobicMM\")\n",
    "uptake_phenoset = util.create_phenotypeset_from_compounds(\n",
    "    metabolites,\n",
    "    base_media=auxo_media,\n",
    "    base_uptake=0,\n",
    "    base_excretion=1000,\n",
    "    global_atom_limits={},\n",
    "    type=\"uptake\"\n",
    ")\n",
    "excretion_phenoset = util.create_phenotypeset_from_compounds(\n",
    "    metabolites,\n",
    "    base_media=auxo_media,\n",
    "    base_uptake=0,\n",
    "    base_excretion=1000,\n",
    "    global_atom_limits={},\n",
    "    type=\"excretion\"\n",
    ")\n",
    "growth_phenoset = util.create_phenotypeset_from_compounds(\n",
    "    metabolites,\n",
    "    base_media=gmm_base_media,\n",
    "    base_uptake=0,\n",
    "    base_excretion=1000,\n",
    "    global_atom_limits={},\n",
    "    type=\"growth\"\n",
    ")\n",
    "phenosets = {\"uptake\":uptake_phenoset,\"excretion\":excretion_phenoset,\"growth\":growth_phenoset}\n",
    "for i,item in enumerate(mag_list):\n",
    "    asvname = item[1]\n",
    "    if i%8 == procid:\n",
    "        if asvname not in probability_finished and asvname not in problemlist:\n",
    "            mdlutl = util.msrecon.get_model(item[1]+model_suffix,model_ws)\n",
    "            reaction_probabilities[asvname] = {}\n",
    "            for rxn in mdlutl.model.reactions:\n",
    "                highest_prob = None\n",
    "                for gene in rxn.genes:\n",
    "                    if gene.id in feature_probabilities[item[1]]:\n",
    "                        if highest_prob == None or feature_probabilities[item[1]][gene.id] > highest_prob:\n",
    "                            highest_prob = feature_probabilities[item[1]][gene.id]\n",
    "                if highest_prob != None:\n",
    "                    rxn.probability = highest_prob\n",
    "                    reaction_probabilities[asvname][rxn.id] = highest_prob\n",
    "            \n",
    "            genome = util.mseedrecon.get_msgenome_from_ontology(mdlutl.model.genome_ref,native_python_api=True,output_ws=None)\n",
    "            reaction_hash = genome.annoont.get_reaction_gene_hash(feature_type=\"gene\")\n",
    "            for rxn in reaction_hash:\n",
    "                highest_prob = None\n",
    "                for gene in reaction_hash[rxn]:\n",
    "                    if gene in feature_probabilities[item[1]]:\n",
    "                        if highest_prob == None or feature_probabilities[item[1]][gene] > highest_prob:\n",
    "                            highest_prob = feature_probabilities[item[1]][gene]\n",
    "                if highest_prob != None and highest_prob >= reaction_probabilities[asvname][rxn]:\n",
    "                    mdlutl.model.reactions.get_by_id(rxn).probability = highest_prob\n",
    "                    reaction_probabilities[asvname][rxn] = highest_prob\n",
    "            \n",
    "            filters = mdlutl.get_attributes(\"gf_filter\")\n",
    "            tests = mdlutl.get_atp_tests(core_template=util.msrecon.core_template,atp_media_filename=util.msrecon.module_dir+\"/data/atp_medias.tsv\",recompute=False)\n",
    "            msgapfill = MSGapfill(\n",
    "                mdlutl,\n",
    "                [util.msrecon.get_template(mdlutl.model.template_ref)],\n",
    "                [],\n",
    "                tests,\n",
    "                blacklist=[],\n",
    "                default_target=\"bio1\",\n",
    "                minimum_obj=0.01,\n",
    "                base_media=None,\n",
    "                base_media_target_element=None\n",
    "            )\n",
    "\n",
    "            #Adding missing transporter for metabolites to gapfilling database\n",
    "            for cpd in metabolites:\n",
    "                if \"EX_\"+cpd+\"_e0\" not in msgapfill.gfmodelutl.model.reactions:\n",
    "                    transport = msgapfill.gfmodelutl.add_transport_and_exchange_for_metabolite(cpd,direction=\"=\",prefix=\"trans\",override=False)\n",
    "\n",
    "            coefficients = {}\n",
    "            gf_penalties = msgapfill.gfpkgmgr.getpkg(\"GapfillingPkg\").gapfilling_penalties\n",
    "            gfrxn = 0\n",
    "            probrxn = 0\n",
    "            otherrxn = 0\n",
    "            for reaction in msgapfill.gfmodelutl.model.reactions:\n",
    "                if reaction.id in reaction_probabilities[asvname]:\n",
    "                    probrxn += 2\n",
    "                    coefficients[\">\"+reaction.id] = 1-reaction_probabilities[asvname][reaction.id]\n",
    "                    coefficients[\"<\"+reaction.id] = 1-reaction_probabilities[asvname][reaction.id]\n",
    "                elif reaction.id in gf_penalties:\n",
    "                    if \"forward\" in gf_penalties[reaction.id]:\n",
    "                        gfrxn += 1\n",
    "                        coefficients[\">\"+reaction.id] = 1+gf_penalties[reaction.id][\"forward\"]\n",
    "                    else:\n",
    "                        otherrxn += 1\n",
    "                        coefficients[\">\"+reaction.id] = 0.95\n",
    "                    if \"reverse\" in gf_penalties[reaction.id]:\n",
    "                        gfrxn += 1\n",
    "                        coefficients[\"<\"+reaction.id] = 1+gf_penalties[reaction.id][\"reverse\"]\n",
    "                    else:\n",
    "                        otherrxn += 1\n",
    "                        coefficients[\"<\"+reaction.id] = 0.95\n",
    "                else:\n",
    "                    otherrxn += 2\n",
    "                    coefficients[\">\"+reaction.id] = 0.95\n",
    "                    coefficients[\"<\"+reaction.id] = 0.95\n",
    "            print(asvname,\"GF:\",gfrxn,\"Prob:\",probrxn,\"Other:\",otherrxn)\n",
    "\n",
    "            msgapfill.prefilter(test_conditions=tests,growth_conditions=[],use_prior_filtering=True,base_filter_only=True)\n",
    "            \n",
    "            gf_phenotype_results[asvname] = {}\n",
    "            for phenoid in phenosets:\n",
    "                gf_phenotype_results[asvname][phenoid] = {}\n",
    "                output = phenosets[phenoid].simulate_phenotypes(\n",
    "                    msgapfill.gfmodelutl,\n",
    "                    multiplier=2,\n",
    "                    add_missing_exchanges=True,\n",
    "                    save_fluxes=False,\n",
    "                    save_reaction_list=True,\n",
    "                    gapfill_negatives=False,\n",
    "                    msgapfill=None,\n",
    "                    test_conditions=None,\n",
    "                    ignore_experimental_data=True,\n",
    "                    flux_coefficients=coefficients\n",
    "                )\n",
    "                for index, row in output[\"details\"].iterrows():\n",
    "                    if \"reactions\" in output[\"data\"][row[\"Phenotype\"]]:\n",
    "                        output[\"data\"][row[\"Phenotype\"]][\"average_probability\"] = 0\n",
    "                        for rxn in output[\"data\"][row[\"Phenotype\"]][\"reactions\"]:\n",
    "                            direction = rxn[0:1]\n",
    "                            rxnid = rxn[1:]\n",
    "                            if direction == \">\":\n",
    "                                if rxnid not in gf_penalties or \"forward\" not in gf_penalties[rxnid]:\n",
    "                                    if rxnid in reaction_probabilities[asvname]:\n",
    "                                        output[\"data\"][row[\"Phenotype\"]][\"average_probability\"] += reaction_probabilities[asvname][rxnid]\n",
    "                                    else:\n",
    "                                        output[\"data\"][row[\"Phenotype\"]][\"average_probability\"] += 0.05\n",
    "                            elif direction == \"<\":\n",
    "                                if rxnid not in gf_penalties or \"reverse\" not in gf_penalties[rxnid]:\n",
    "                                    if rxnid in reaction_probabilities[asvname]:\n",
    "                                        output[\"data\"][row[\"Phenotype\"]][\"average_probability\"] += reaction_probabilities[asvname][rxnid]\n",
    "                                    else:\n",
    "                                        output[\"data\"][row[\"Phenotype\"]][\"average_probability\"] += 0.05\n",
    "                        output[\"data\"][row[\"Phenotype\"]][\"average_probability\"] = output[\"data\"][row[\"Phenotype\"]][\"average_probability\"]/len(output[\"data\"][row[\"Phenotype\"]][\"reactions\"])\n",
    "                    gf_phenotype_results[asvname][phenoid][row[\"Phenotype\"]] = output[\"data\"][row[\"Phenotype\"]]\n",
    "            probability_finished.append(asvname)\n",
    "            util.save(\"new_gf_phenotype_results_\"+str(procid),gf_phenotype_results)\n",
    "            util.save(\"reaction_probabilities\"+str(procid),reaction_probabilities)\n",
    "            util.save(\"probability_finished_\"+str(procid),probability_finished)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consolidating gapfilling phenotype data sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run cliffcommutil.py\n",
    "consolidated_gf_results = util.load(\"consolidated_gf_results\",{})\n",
    "reaction_probabilities = util.load(\"reaction_probabilities\",{})\n",
    "for i in range(0,8,1):\n",
    "    phenotype_gf_results = util.load(\"gf_phenotype_results_\"+str(i))\n",
    "    part_reaction_probabilities = util.load(\"reaction_probabilities\"+str(i))\n",
    "    for asvname in phenotype_gf_results:\n",
    "        consolidated_gf_results[asvname] = phenotype_gf_results[asvname]\n",
    "         reaction_probabilities[asvname] = part_reaction_probabilities[asvname]\n",
    "util.save(\"consolidated_gf_results\",consolidated_gf_results)\n",
    "util.save(\"reaction_probabilities\",reaction_probabilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing proper gapfill and filtering bad predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run cliffcommutil.py\n",
    "consolidated_gf_results = util.load(\"consolidated_gf_results\")\n",
    "reaction_probabilities = util.load(\"reaction_probabilities\")\n",
    "mag_to_model = util.load(\"mag_to_model\")\n",
    "studies = [\"uptake\",\"excretion\",\"growth\"]\n",
    "for asvname in consolidated_gf_results:\n",
    "    modelname = mag_to_model(asvname)\n",
    "    #Getting base model\n",
    "    mdlutl = util.msrecon.get_model(modelname,186678)\n",
    "    \n",
    "    for study in studies:\n",
    "        if study not in consolidated_gf_results[asvname]:\n",
    "            continue\n",
    "        for phenotype in consolidated_gf_results[asvname][study]:\n",
    "            if \"reactions\" in consolidated_gf_results[asvname][study][phenotype]:\n",
    "                consolidated_gf_results[asvname][study][phenotype][\"new_probability\"] = 0\n",
    "                consolidated_gf_results[asvname][study][phenotype][\"probrxn\"] = 0\n",
    "                consolidated_gf_results[asvname][study][phenotype][\"otherrxn\"] = 0\n",
    "                consolidated_gf_results[asvname][study][phenotype][\"origgfrxn\"] = 0\n",
    "                consolidated_gf_results[asvname][study][phenotype][\"new_gf\"] = 0\n",
    "                consolidated_gf_results[asvname][study][phenotype][\"new_gf_reactions\"] = []\n",
    "                found = False\n",
    "                for rxn in consolidated_gf_results[asvname][study][phenotype][\"reactions\"]:\n",
    "                    direction = rxn[0:1]\n",
    "                    rxnid = rxn[1:]\n",
    "                    if rxnid[0:3] == \"EX_\" and rxnid[3:11] == phenotype:\n",
    "                        found = True\n",
    "                    if rxnid not in mdlutl.model.reactions:\n",
    "                        consolidated_gf_results[asvname][study][phenotype][\"new_gf_reactions\"].append(rxn)\n",
    "                        consolidated_gf_results[asvname][study][phenotype][\"new_gf\"] += 1\n",
    "                    elif direction == \">\":\n",
    "                        if mdlutl.model.reactions.get_by_id(rxnid).upper_bound <= 0:\n",
    "                            consolidated_gf_results[asvname][study][phenotype][\"new_gf_reactions\"].append(rxn)\n",
    "                            consolidated_gf_results[asvname][study][phenotype][\"new_gf\"] += 1\n",
    "                        elif rxnid in reaction_probabilities[asvname]:\n",
    "                            consolidated_gf_results[asvname][study][phenotype][\"new_probability\"] += reaction_probabilities[asvname][rxnid]\n",
    "                            consolidated_gf_results[asvname][study][phenotype][\"probrxn\"] += 1\n",
    "                        elif rxnid[0:3] != \"bio\" and rxnid[0:3] != \"EX_\" and rxnid[0:3] != \"DM_\" and len(mdlutl.model.reactions.get_by_id(rxnid).genes) == 0:\n",
    "                            consolidated_gf_results[asvname][study][phenotype][\"origgfrxn\"] += 1\n",
    "                        else:\n",
    "                            consolidated_gf_results[asvname][study][phenotype][\"otherrxn\"] += 1\n",
    "                            consolidated_gf_results[asvname][study][phenotype][\"new_probability\"] += 0.05  \n",
    "                    elif direction == \"<\":\n",
    "                        if mdlutl.model.reactions.get_by_id(rxnid).lower_bound >= 0:\n",
    "                            consolidated_gf_results[asvname][study][phenotype][\"new_gf_reactions\"].append(rxn)\n",
    "                            consolidated_gf_results[asvname][study][phenotype][\"new_gf\"] += 1\n",
    "                        elif rxnid in reaction_probabilities[asvname]:\n",
    "                            consolidated_gf_results[asvname][study][phenotype][\"new_probability\"] += reaction_probabilities[asvname][rxnid]\n",
    "                            consolidated_gf_results[asvname][study][phenotype][\"probrxn\"] += 1\n",
    "                        elif rxnid[0:3] != \"bio\" and rxnid[0:3] != \"EX_\" and rxnid[0:3] != \"DM_\" and len(mdlutl.model.reactions.get_by_id(rxnid).genes) == 0:\n",
    "                            consolidated_gf_results[asvname][study][phenotype][\"origgfrxn\"] += 1\n",
    "                        else:\n",
    "                            consolidated_gf_results[asvname][study][phenotype][\"otherrxn\"] += 1\n",
    "                            consolidated_gf_results[asvname][study][phenotype][\"new_probability\"] += 0.05  \n",
    "                totalrxn = consolidated_gf_results[asvname][study][phenotype][\"probrxn\"]+consolidated_gf_results[asvname][study][phenotype][\"new_gf\"]+consolidated_gf_results[asvname][study][phenotype][\"otherrxn\"]\n",
    "                consolidated_gf_results[asvname][study][phenotype][\"new_probability\"] = consolidated_gf_results[asvname][study][phenotype][\"new_probability\"]/totalrxn\n",
    "\n",
    "                if not found:\n",
    "                    consolidated_gf_results[asvname][study][phenotype][\"original_objective_value\"] = consolidated_gf_results[asvname][study][phenotype][\"objective_value\"]\n",
    "                    consolidated_gf_results[asvname][study][phenotype][\"objective_value\"] = 0\n",
    "                    consolidated_gf_results[asvname][study][phenotype][\"class\"] = \"N\"\n",
    "                    consolidated_gf_results[asvname][study][phenotype][\"positive\"] = False\n",
    "                    consolidated_gf_results[asvname][study][phenotype][\"new_probability\"] = 0\n",
    "util.save(\"consolidated_gf_results\",consolidated_gf_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Printing matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run cliffcommutil.py\n",
    "consolidated_gf_results = util.load(\"consolidated_gf_results\")\n",
    "metabolites = util.load(\"metabolites\")\n",
    "metabolite_names = util.load(\"metabolite_names\")\n",
    "mag_abundances = util.load(\"mag_abundances\")\n",
    "total_mag_abundances = util.load(\"total_mag_abundances\")\n",
    "records = {\n",
    "    \"uptake_prob\":[{\"Sample\":\"Name\"}],\n",
    "    \"excretion_prob\":[{\"Sample\":\"Name\"}],\n",
    "    \"growth_prob\":[{\"Sample\":\"Name\"}],\n",
    "}\n",
    "types = [\"uptake\",\"excretion\",\"growth\"]\n",
    "for met in metabolites:\n",
    "    for item in records:\n",
    "        records[item][0][met] = metabolite_names[met]\n",
    "for sample in mag_abundances:\n",
    "    new_record = {\n",
    "        \"uptake_prob\":{\"Sample\":sample},\n",
    "        \"excretion_prob\":{\"Sample\":sample},\n",
    "        \"growth_prob\":{\"Sample\":sample}\n",
    "    }\n",
    "    for metabolite in metabolites:\n",
    "        for item in new_record:\n",
    "            new_record[item][metabolite] = 0\n",
    "    for asvname in mag_abundances[sample]:\n",
    "        for metabolite in metabolites:\n",
    "            for currtype in types:\n",
    "                if currtype in consolidated_gf_results[asvname]:\n",
    "                    if metabolite in consolidated_gf_results[asvname][currtype] and \"new_probability\" in consolidated_gf_results[asvname][currtype][metabolite]:\n",
    "                        new_record[currtype+\"_prob\"][metabolite] += mag_abundances[sample][asvset]/total_mag_abundances[sample]*consolidated_gf_results[asvname][currtype][metabolite][\"new_probability\"]\n",
    "    for item in records:\n",
    "        records[item].append(new_record[item])\n",
    "#Printing interation matrices\n",
    "for item in records:\n",
    "    df = pd.DataFrame.from_records(records[item])\n",
    "    df.to_csv(util.output_dir+\"/Sample\"+item+\"Interactions.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Printing ASV data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run cliffcommutil.py\n",
    "consolidated_gf_results = util.load(\"consolidated_gf_results\")\n",
    "metabolites = util.load(\"metabolites\")\n",
    "metabolite_names = util.load(\"metabolite_names\")\n",
    "mag_list = util.load(\"mag_list\")\n",
    "records = {\n",
    "    \"uptake_prob\":[{\"MAG\":\"Name\"}],\n",
    "    \"excretion_prob\":[{\"MAG\":\"Name\"}],\n",
    "    \"growth_prob\":[{\"MAG\":\"Name\"}],\n",
    "    \"uptake_data\":[{\"MAG\":\"Name\"}],\n",
    "    \"excretion_data\":[{\"MAG\":\"Name\"}],\n",
    "    \"growth_data\":[{\"MAG\":\"Name\"}],\n",
    "}\n",
    "types = [\"uptake\",\"excretion\",\"growth\"]\n",
    "for met in metabolites:\n",
    "    for item in records:\n",
    "        records[item][0][met] = metabolite_names[met]\n",
    "for item in mag_list:\n",
    "    asvname = item[1]\n",
    "    if asvname not in consolidated_gf_results:\n",
    "        print(\"No data for \",asvname)\n",
    "        continue\n",
    "    new_record = {}\n",
    "    for currtype in types:\n",
    "        new_record[currtype+\"_prob\"] = {\"MAG\":asvname}\n",
    "        new_record[currtype+\"_data\"] = {\"MAG\":asvname}\n",
    "    for metabolite in metabolites:\n",
    "        for currtype in types:\n",
    "            if currtype in consolidated_gf_results[asvname]:\n",
    "                if metabolite in consolidated_gf_results[asvname][currtype] and \"new_probability\" in consolidated_gf_results[asvname][currtype][metabolite]:\n",
    "                    new_record[currtype+\"_prob\"][metabolite] = consolidated_gf_results[asvname][currtype][metabolite][\"new_probability\"]\n",
    "                    new_record[currtype+\"_data\"][metabolite] = str(consolidated_gf_results[asvname][currtype][metabolite][\"probrxn\"])\n",
    "                    new_record[currtype+\"_data\"][metabolite] += \"/\"+str(consolidated_gf_results[asvname][currtype][metabolite][\"otherrxn\"])\n",
    "                    new_record[currtype+\"_data\"][metabolite] += \"/\"+str(consolidated_gf_results[asvname][currtype][metabolite][\"origgfrxn\"])\n",
    "                    new_record[currtype+\"_data\"][metabolite] += \"/\"+str(consolidated_gf_results[asvname][currtype][metabolite][\"new_gf\"])\n",
    "                    new_record[currtype+\"_data\"][metabolite] += \"/\"+str(consolidated_gf_results[asvname][currtype][metabolite][\"gapfill_count\"])\n",
    "                    new_record[currtype+\"_data\"][metabolite] += \"/\"+str(consolidated_gf_results[asvname][currtype][metabolite][\"reaction_count\"])\n",
    "    for item in records:\n",
    "        records[item].append(new_record[item])\n",
    "#Printing interation matrices\n",
    "for item in records:\n",
    "    df = pd.DataFrame.from_records(records[item])\n",
    "    df.to_csv(util.output_dir+\"/MAG\"+item+\"Interactions.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gapfilling models based on gapfilling simulation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run cliffcommutil.py\n",
    "import numpy as np\n",
    "consolidated_gf_results = util.load(\"consolidated_gf_results\")\n",
    "finished_models = util.load(\"finished_models\",{})\n",
    "metabolites = util.load(\"metabolites\")\n",
    "reactions_to_add = {}\n",
    "\n",
    "for asvname in consolidated_gf_results:\n",
    "    if asvname not in finished_models:\n",
    "        mdlutl = util.msrecon.get_model(asvname+\".ASV.mdl\",181152)\n",
    "        types = [\"uptake\",\"excretion\",\"growth\"]\n",
    "        reactions_to_add[asvname] = {}\n",
    "        for currtype in types:\n",
    "            problist = []\n",
    "            for metabolite in metabolites:\n",
    "                if metabolite in consolidated_gf_results[asvname][currtype] and \"new_probability\" in consolidated_gf_results[asvname][currtype][metabolite]:\n",
    "                    if consolidated_gf_results[asvname][currtype][metabolite][\"new_probability\"] > 0:\n",
    "                        problist.append(consolidated_gf_results[asvname][currtype][metabolite][\"new_probability\"])\n",
    "            if len(problist) > 0:\n",
    "                ave = np.array(problist).mean()\n",
    "                stdev = np.array(problist).std()\n",
    "                for metabolite in metabolites:\n",
    "                    if metabolite in consolidated_gf_results[asvname][currtype] and \"new_probability\" in consolidated_gf_results[asvname][currtype][metabolite]:\n",
    "                        if consolidated_gf_results[asvname][currtype][metabolite][\"new_probability\"] > 0:\n",
    "                            consolidated_gf_results[asvname][currtype][metabolite][\"zscore\"] = (consolidated_gf_results[asvname][currtype][metabolite][\"new_probability\"]-ave)/stdev\n",
    "                            if consolidated_gf_results[asvname][currtype][metabolite][\"zscore\"] >= -1 and \"reactions\" in consolidated_gf_results[asvname][currtype][metabolite]:\n",
    "                                for rxn in consolidated_gf_results[asvname][currtype][metabolite][\"reactions\"]:\n",
    "                                    direction = rxn[0:1]\n",
    "                                    rxnid = rxn[1:]\n",
    "                                    if rxnid not in mdlutl.model.reactions:\n",
    "                                        if rxnid not in reactions_to_add[asvname]:\n",
    "                                            reactions_to_add[asvname][rxnid] = {}\n",
    "                                        reactions_to_add[asvname][rxnid][direction] = consolidated_gf_results[asvname][currtype][metabolite][\"zscore\"]\n",
    "                                    elif direction == \">\":\n",
    "                                        if mdlutl.model.reactions.get_by_id(rxnid).upper_bound <= 0:\n",
    "                                            if rxnid not in reactions_to_add[asvname]:\n",
    "                                                reactions_to_add[asvname][rxnid] = {}\n",
    "                                            reactions_to_add[asvname][rxnid][direction] = consolidated_gf_results[asvname][currtype][metabolite][\"zscore\"]\n",
    "                                    elif direction == \"<\":\n",
    "                                        if mdlutl.model.reactions.get_by_id(rxnid).lower_bound >= 0:\n",
    "                                            if rxnid not in reactions_to_add[asvname]:\n",
    "                                                reactions_to_add[asvname][rxnid] = {}\n",
    "                                            reactions_to_add[asvname][rxnid][direction] = consolidated_gf_results[asvname][currtype][metabolite][\"zscore\"]\n",
    "        util.save(\"consolidated_gf_results\",consolidated_gf_results)\n",
    "        msgapfill = MSGapfill(\n",
    "            mdlutl,\n",
    "            [util.msrecon.get_template(mdlutl.model.template_ref)],\n",
    "            [],\n",
    "            [],\n",
    "            blacklist=[],\n",
    "            default_target=\"bio1\",\n",
    "            minimum_obj=0.01,\n",
    "            base_media=None,\n",
    "            base_media_target_element=None\n",
    "        )\n",
    "        for cpd in metabolites:\n",
    "            if \"EX_\"+cpd+\"_e0\" not in msgapfill.gfmodelutl.model.reactions:\n",
    "                transport = msgapfill.gfmodelutl.add_transport_and_exchange_for_metabolite(cpd,direction=\"=\",prefix=\"trans\",override=False)\n",
    "        for rxnid in reactions_to_add[asvname]:\n",
    "            if rxnid in msgapfill.gfmodel.reactions:\n",
    "                rxn = msgapfill.gfmodel.reactions.get_by_id(rxnid)\n",
    "                rxn = rxn.copy()\n",
    "                mdlutl.model.add_reactions([rxn])\n",
    "                rxn.upper_bound = 0\n",
    "                rxn.lower_bound = 0\n",
    "                if \">\" in reactions_to_add[asvname][rxnid]:\n",
    "                    rxn.upper_bound = 100\n",
    "                if \"<\" in reactions_to_add[asvname][rxnid]:\n",
    "                    rxn.lower_bound = -100\n",
    "            else:\n",
    "                print(asvname,\"Missing reaction\",rxnid,reactions_to_add[asvname][rxnid])\n",
    "        util.msrecon.save_model(mdlutl,181152,asvname+\".ASV.mdl.gf\")\n",
    "        finished_models[asvname] = 1\n",
    "    util.save(\"finished_models\",finished_models)\n",
    "util.save(\"reactions_to_add\",reactions_to_add)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building and saving community model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run cliffcommutil.py\n",
    "import cobra\n",
    "mag_list = util.load(\"mag_list\")\n",
    "mag_abundances = util.load(\"mag_abundances\")\n",
    "total_mag_abundances = util.load(\"total_mag_abundances\")\n",
    "\n",
    "for sample in mag_abundances:\n",
    "    member_models = []\n",
    "    member_names = []\n",
    "    member_abundances = {}\n",
    "    asv_hash = {}\n",
    "    for mag in mag_abundances[sample]:\n",
    "        if mag_abundances[sample][mag]/total_mag_abundances[sample] > 0.01:\n",
    "            mdlutl = util.msrecon.get_model(asvname+\".ASV.mdl.gf\",181152)\n",
    "            member_models.append(mdlutl.model)\n",
    "            member_names.append(asvname)\n",
    "            member_abundances[asvname] = mag_abundances[sample][mag]/total_mag_abundances[sample]\n",
    "    comm_model = MSCommunity.build_from_species_models(\n",
    "        member_models,\n",
    "        mdlid=sample,\n",
    "        name=sample,\n",
    "        names=member_names,\n",
    "        abundances=member_abundances\n",
    "    )\n",
    "    cobra.io.save_json_model(comm_model.model, \"models/\"+sample+'.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running community model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run cliffcommutil.py\n",
    "procid = 0\n",
    "metabolites = util.load(\"metabolites\")\n",
    "metabolomics_data = util.load(\"metabolomics_data\")\n",
    "feature_probabilities = util.load(\"feature_probabilities\")\n",
    "community_model_data = util.load(\"community_model_data\")\n",
    "from optlang.symbolics import Zero, add\n",
    "import cobra\n",
    "\n",
    "complete_media = util.msrecon.get_media(\"KBaseMedia/Complete\")\n",
    "\n",
    "model_list = [\"RC-ABX_-1.5\",\"RC-ABX_1.5\",\"RC-ABX_4.0\",\"RC-ABX_6.0\",\"RC-ABX_9.0\",\"RC-ABX_12.5\"]\n",
    "output = {}\n",
    "rxn_record_hash = {}\n",
    "records = [\n",
    "    {\"id\":\"max_growth\"},\n",
    "    {\"id\":\"carbon_uptake\"},\n",
    "    {\"id\":\"flux fitting objective\"},\n",
    "    {\"id\":\"minimum probability objective\"},\n",
    "]\n",
    "for modelid in model_list:\n",
    "    output[modelid] = {}\n",
    "    base_model = cobra.io.load_json_model(\"models/\"+modelid+'.json')\n",
    "    current_comm_model = MSCommunity(\n",
    "        model=base_model,\n",
    "        names=community_model_data[modelid][\"names\"]\n",
    "    )\n",
    "    #loadedmodel.solver = 'gurobi'\n",
    "    dipeptide_exchanges = [\n",
    "        \"EX_cpd11591_e0\",\n",
    "        \"EX_cpd11589_e0\",\n",
    "        \"EX_cpd15605_e0\",\n",
    "        \"EX_cpd11588_e0\",\n",
    "        \"EX_cpd11583_e0\",\n",
    "        \"EX_cpd11580_e0\",\n",
    "        \"EX_cpd11593_e0\",\n",
    "        \"EX_cpd11585_e0\",\n",
    "        \"EX_cpd11586_e0\",\n",
    "        \"EX_cpd15604_e0\",\n",
    "        \"EX_cpd11581_e0\",\n",
    "        \"EX_cpd01017_e0\",\n",
    "        \"EX_cpd11590_e0\",\n",
    "        \"EX_cpd11592_e0\",\n",
    "        \"EX_cpd11584_e0\",\n",
    "        \"EX_cpd00731_e0\",\n",
    "        \"EX_cpd15603_e0\",\n",
    "        \"EX_cpd11587_e0\",\n",
    "        \"EX_cpd11582_e0\",\n",
    "        \"EX_cpd15606_e0\",\n",
    "        \"EX_cpd03424_e0\",\n",
    "        \"EX_cpd00423_e0\",\n",
    "        \"EX_cpd00080_e0\",\n",
    "        \"EX_cpd02233_e0\",\n",
    "        \"EX_cpd00355_e0\",\n",
    "        \"EX_cpd00235_e0\",\n",
    "        \"EX_cpd00079_e0\",\n",
    "        \"EX_cpd01912_e0\"\n",
    "    ]\n",
    "    reaction_probabilities = {}\n",
    "    for rxn in base_model.reactions:\n",
    "        highest_prob = None\n",
    "        for gene in rxn.genes:\n",
    "            if gene.id in feature_probabilities:\n",
    "                if highest_prob == None or feature_probabilities[gene.id] > highest_prob:\n",
    "                    highest_prob = feature_probabilities[gene.id]\n",
    "        if highest_prob != None:\n",
    "            rxn.probability = highest_prob\n",
    "            reaction_probabilities[rxn.id] = highest_prob\n",
    "        elif rxn.id[0:3] != \"bio\" and rxn.id[0:3] != \"EX_\" and rxn.id[0:3] != \"DM_\" and len(rxn.genes) == 0:\n",
    "            reaction_probabilities[rxn.id] = 0\n",
    "        else:\n",
    "            reaction_probabilities[rxn.id] = 0.05\n",
    "    min_prob = 0.05\n",
    "    prob_exp = 1\n",
    "    ex_weight = 1\n",
    "    kinetics_coef = 750\n",
    "    mdlutl = current_comm_model.mdlutl\n",
    "    pkgmgr = MSPackageManager.get_pkg_mgr(mdlutl)\n",
    "    #Setting media\n",
    "    pkgmgr.getpkg(\"KBaseMediaPkg\").build_package(complete_media)\n",
    "    #Adding commkinetic constraints\n",
    "    pkgmgr.getpkg(\"CommKineticPkg\").build_package(kinetics_coef, current_comm_model)\n",
    "    #Adding elemental uptake constraints\n",
    "    pkgmgr.getpkg(\"ElementUptakePkg\").build_package({\"C\": 300})\n",
    "    for rxn in base_model.reactions:\n",
    "        if \"EX_\" == rxn.id[0:3]:\n",
    "            currrxn = current_comm_model.model.reactions.get_by_id(rxn.id)\n",
    "            if rxn.id in dipeptide_exchanges:\n",
    "                currrxn.lower_bound = 0\n",
    "                currrxn.upper_bound = 0\n",
    "            else:\n",
    "                if currrxn.lower_bound < 0:\n",
    "                    currrxn.lower_bound = -1000\n",
    "                if currrxn.upper_bound > 0:\n",
    "                    currrxn.upper_bound = 1000\n",
    "    currrxn = current_comm_model.model.reactions.get_by_id(\"EX_cpd00007_e0\")\n",
    "    currrxn.lower_bound = -20\n",
    "    #Maximize biomass production\n",
    "    mdlutl.model.objective = mdlutl.model.problem.Objective(Zero, direction=\"max\")\n",
    "    mdlutl.model.objective.set_linear_coefficients({mdlutl.model.reactions.bio1.forward_variable: 1})\n",
    "    first_solution = mdlutl.model.optimize()\n",
    "    output[modelid][\"max_growth\"] = first_solution.objective_value\n",
    "    output[modelid][\"carbon_uptake\"] = pkgmgr.getpkg(\"ElementUptakePkg\").variables[\"elements\"][\"C\"].primal\n",
    "    records[0][modelid] = output[modelid][\"max_growth\"]\n",
    "    records[1][modelid] = output[modelid][\"carbon_uptake\"]\n",
    "    print(modelid+\" growth:\", output[modelid][\"max_growth\"])\n",
    "    print(modelid+\"carbon uptake:\",output[modelid][\"carbon_uptake\"])\n",
    "    \n",
    "    with open(util.output_dir+\"/\"+modelid+\"-growth.lp\", \"w\") as out:\n",
    "        out.write(str(mdlutl.model.solver))\n",
    "\n",
    "    if str(output[modelid][\"max_growth\"]) == \"nan\":\n",
    "        print(\"Skipping condition due to infeasibility\", modelid)\n",
    "        continue\n",
    "    #Constraining to 70% of community biomass\n",
    "    pkgmgr.getpkg(\"ObjConstPkg\").build_package(output[modelid][\"max_growth\"] * 0.5, None)\n",
    "    #Creating minimal probability objective\n",
    "    coef = {}\n",
    "    flux_fitting_target = {}\n",
    "    for rxn in base_model.reactions:\n",
    "        if \"rxn\" == rxn.id[0:3]:\n",
    "            probability = reaction_probabilities[rxn.id]\n",
    "            currrxn = mdlutl.model.reactions.get_by_id(rxn.id)\n",
    "            coef.update(\n",
    "                {\n",
    "                    currrxn.forward_variable: max(\n",
    "                        min_prob, (1 - float(probability) ** prob_exp)\n",
    "                    )\n",
    "                }\n",
    "            )\n",
    "            coef.update(\n",
    "                {\n",
    "                    currrxn.reverse_variable: max(\n",
    "                        min_prob, (1 - float(probability) ** prob_exp)\n",
    "                    )\n",
    "                }\n",
    "            )\n",
    "        elif \"EX_\" == rxn.id[0:3]:\n",
    "            currrxn = mdlutl.model.reactions.get_by_id(rxn.id)\n",
    "            if rxn.id[3:11] in metabolomics_data:\n",
    "                flux_fitting_target[rxn.id] = -1*output[modelid][\"max_growth\"]*metabolomics_data[rxn.id[3:11]][modelid]\n",
    "            coef.update({currrxn.forward_variable: ex_weight})\n",
    "            coef.update({currrxn.reverse_variable: ex_weight})\n",
    "\n",
    "    #Solving the LP\n",
    "    #pkgmgr.getpkg(\"FluxFittingPkg\").build_package({\n",
    "    #    \"target_flux\": flux_fitting_target,\n",
    "    #    \"totalflux\": 0,\n",
    "    #    \"set_objective\": 1,\n",
    "    #    \"default_rescaling\": 0.1,\n",
    "    #    \"rescale_vfit_by_flux\": True\n",
    "    #})\n",
    "    stuck_reactions = {}\n",
    "    for iteration in range(1,11,1):\n",
    "        print(\"Iteration\",iteration)\n",
    "        for rxn in flux_fitting_target:\n",
    "            if rxn in stuck_reactions:\n",
    "                continue\n",
    "            currrxn = mdlutl.model.reactions.get_by_id(rxn)\n",
    "            starting_point = first_solution.fluxes[rxn]\n",
    "            distance = abs(flux_fitting_target[rxn] - starting_point)\n",
    "            original_upper = currrxn.upper_bound\n",
    "            original_lower = currrxn.lower_bound\n",
    "            if starting_point > flux_fitting_target[rxn]:\n",
    "                if starting_point-iteration*distance/10 < currrxn.upper_bound:\n",
    "                    currrxn.lower_bound = starting_point-iteration*distance/10\n",
    "                    currrxn.upper_bound = starting_point-iteration*distance/10\n",
    "                else:\n",
    "                    currrxn.upper_bound = starting_point-iteration*distance/10\n",
    "                    currrxn.lower_bound = starting_point-iteration*distance/10\n",
    "            else:\n",
    "                if flux_fitting_target[rxn]-(10-iteration)*distance/10 < currrxn.upper_bound:\n",
    "                    currrxn.lower_bound = flux_fitting_target[rxn]-(10-iteration)*distance/10\n",
    "                    currrxn.upper_bound = flux_fitting_target[rxn]-(10-iteration)*distance/10\n",
    "                else:\n",
    "                    currrxn.upper_bound = flux_fitting_target[rxn]-(10-iteration)*distance/10\n",
    "                    currrxn.lower_bound = flux_fitting_target[rxn]-(10-iteration)*distance/10\n",
    "            solution = mdlutl.model.optimize()\n",
    "            if solution.status != \"optimal\":\n",
    "                print(\"Stuck\",rxn,starting_point,flux_fitting_target[rxn],original_upper)\n",
    "                stuck_reactions[rxn] = 1\n",
    "                if original_upper >= currrxn.lower_bound:\n",
    "                    currrxn.upper_bound = original_upper\n",
    "                    currrxn.lower_bound = original_lower\n",
    "                else:\n",
    "                    currrxn.lower_bound = original_lower\n",
    "                    currrxn.upper_bound = original_upper\n",
    "    for rxn in flux_fitting_target:\n",
    "        currrxn = mdlutl.model.reactions.get_by_id(rxn)\n",
    "        print(currrxn.id,currrxn.lower_bound,currrxn.upper_bound)\n",
    "    #solution = mdlutl.model.optimize()\n",
    "    #output[modelid][\"flux fitting objective\"] = solution.objective_value\n",
    "    \n",
    "    #with open(util.output_dir+\"/\"+modelid+\"-fitting.lp\", \"w\") as out:\n",
    "    #    out.write(str(mdlutl.model.solver))\n",
    "\n",
    "    #records[2][modelid] = output[modelid][\"flux fitting objective\"]\n",
    "    #for rxn in flux_fitting_target:\n",
    "    #    currrxn = current_comm_model.model.reactions.get_by_id(rxn)\n",
    "    #    if solution.fluxes[rxn] > 0:\n",
    "    #        currrxn.upper_bound = solution.fluxes[rxn]\n",
    "    #        currrxn.lower_bound = solution.fluxes[rxn]\n",
    "    #    elif solution.fluxes[rxn] < 0:\n",
    "    #        currrxn.lower_bound = solution.fluxes[rxn]\n",
    "    #        currrxn.upper_bound = solution.fluxes[rxn]\n",
    "    #Setting probability minimization objective\n",
    "    mdlutl.model.objective = mdlutl.model.problem.Objective(Zero, direction=\"min\")\n",
    "    mdlutl.model.objective.set_linear_coefficients(coef)\n",
    "    solution = mdlutl.model.optimize()\n",
    "    if solution.status != \"optimal\":\n",
    "        while solution.status != \"optimal\":\n",
    "            print(\"Infeasible: reducing objective constraint\",0.9*mdlutl.pkgmgr.getpkg(\"ObjConstPkg\").constraints[\"objc\"][\"1\"].lb)\n",
    "            mdlutl.pkgmgr.getpkg(\"ObjConstPkg\").constraints[\"objc\"][\"1\"].lb = 0.9*mdlutl.pkgmgr.getpkg(\"ObjConstPkg\").constraints[\"objc\"][\"1\"].lb\n",
    "            solution = mdlutl.model.optimize()\n",
    "    output[modelid][\"minimum probability objective\"] = solution.objective_value\n",
    "    \n",
    "    with open(util.output_dir+\"/\"+modelid+\"-final.lp\", \"w\") as out:\n",
    "        out.write(str(mdlutl.model.solver))\n",
    "\n",
    "    records[3][modelid] = output[modelid][\"minimum probability objective\"]\n",
    "    output[modelid][\"solution\"] = {}\n",
    "    for rxn in mdlutl.model.reactions:\n",
    "        if rxn.id not in rxn_record_hash:\n",
    "            rxn_record_hash[rxn.id] = {\n",
    "                \"id\":rxn.id,\n",
    "            }\n",
    "            for item in model_list:\n",
    "                rxn_record_hash[rxn.id][item] = None\n",
    "            records.append(rxn_record_hash[rxn.id])\n",
    "        rxn_record_hash[rxn.id][modelid] = solution.fluxes[rxn.id]\n",
    "        output[modelid][\"solution\"][rxn.id] = solution.fluxes[rxn.id]\n",
    "    util.save(\"CommunityFluxSolution2\", output)\n",
    "    df = DataFrame.from_records(records)\n",
    "    df.to_csv(util.output_dir+\"/CommunityFluxSolution2.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "modelseed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
