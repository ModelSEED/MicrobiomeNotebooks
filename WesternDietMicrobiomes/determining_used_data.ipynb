{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \"# asv_abundances = asv_abundances if \\\"asv_abundances\\\" in locals() else read_csv(\\\"metabolomics data/merged_otu_table.txt\\\", sep=\\\"\\\\t\\\").set_index(\\\"taxonID\\\")\\n\",\n",
      "    \"asv_abundances = read_csv(\\\"metabolomics data/merged_otu_table.txt\\\", sep=\\\"\\\\t\\\").set_index(\\\"taxonID\\\")\\n\",\n",
      "    \"    df = read_csv(df_path).fillna(0)\\n\",\n",
      "    \"    df = read_csv(data_path).set_index(indexName).fillna(0)\\n\",\n",
      "    \"#         df = read_csv(file)\\n\",\n",
      "    \"    df = read_csv(data_path).set_index(\\\"ASV\\\").drop(\\\"Name\\\", axis=0).astype(float)\\n\",\n",
      "    \"    df = read_csv(data_path).set_index(\\\"ASV\\\")\\n\",\n",
      "    \"    sample = read_csv(sample_CSV_path).set_index(\\\"Sample\\\").drop(\\\"Name\\\", axis=0).astype(float)\\n\",\n",
      "    \"    sample = read_csv(sample_CSV_path).set_index(\\\"Sample\\\").drop(\\\"Name\\\", axis=0).astype(float)\\n\",\n",
      "      \"Cell \\u001b[0;32mIn [227], line 2\\u001b[0m\\n\\u001b[1;32m      1\\u001b[0m metabolomics \\u001b[38;5;241m=\\u001b[39m read_csv(\\u001b[38;5;124m\\\"\\u001b[39m\\u001b[38;5;124m../../metabolomics data/day_averaged_concentrations_recDay.csv\\u001b[39m\\u001b[38;5;124m\\\"\\u001b[39m)\\n\\u001b[0;32m----> 2\\u001b[0m \\u001b[38;5;28mprint\\u001b[39m([met \\u001b[38;5;28;01mfor\\u001b[39;00m met \\u001b[38;5;129;01min\\u001b[39;00m metabolomics\\u001b[38;5;241m.\\u001b[39mindex \\u001b[38;5;28;01mif\\u001b[39;00m \\u001b[38;5;124m\\\"\\u001b[39m\\u001b[38;5;124mPBX\\u001b[39m\\u001b[38;5;124m\\\"\\u001b[39m \\u001b[38;5;129;01mnot\\u001b[39;00m \\u001b[38;5;129;01min\\u001b[39;00m met])\\n\",\n",
      "      \"Cell \\u001b[0;32mIn [227], line 2\\u001b[0m, in \\u001b[0;36m<listcomp>\\u001b[0;34m(.0)\\u001b[0m\\n\\u001b[1;32m      1\\u001b[0m metabolomics \\u001b[38;5;241m=\\u001b[39m read_csv(\\u001b[38;5;124m\\\"\\u001b[39m\\u001b[38;5;124m../../metabolomics data/day_averaged_concentrations_recDay.csv\\u001b[39m\\u001b[38;5;124m\\\"\\u001b[39m)\\n\\u001b[0;32m----> 2\\u001b[0m \\u001b[38;5;28mprint\\u001b[39m([met \\u001b[38;5;28;01mfor\\u001b[39;00m met \\u001b[38;5;129;01min\\u001b[39;00m metabolomics\\u001b[38;5;241m.\\u001b[39mindex \\u001b[38;5;28;01mif\\u001b[39;00m \\u001b[38;5;124;43m\\\"\\u001b[39;49m\\u001b[38;5;124;43mPBX\\u001b[39;49m\\u001b[38;5;124;43m\\\"\\u001b[39;49m\\u001b[43m \\u001b[49m\\u001b[38;5;129;43;01mnot\\u001b[39;49;00m\\u001b[43m \\u001b[49m\\u001b[38;5;129;43;01min\\u001b[39;49;00m\\u001b[43m \\u001b[49m\\u001b[43mmet\\u001b[49m])\\n\",\n",
      "    \"# asv_abundances = asv_abundances if \\\"asv_abundances\\\" in locals() else read_csv(\\\"metabolomics data/merged_otu_table.txt\\\", sep=\\\"\\\\t\\\").set_index(\\\"taxonID\\\")\\n\",\n",
      "    \"asv_abundances = read_csv(\\\"metabolomics data/merged_otu_table.txt\\\", sep=\\\"\\\\t\\\").set_index(\\\"taxonID\\\")\\n\",\n",
      "    \"    with open(escherJSON_path, \\\"r\\\") as jsonIn\n",
      "    \"with open(path, \\\"r\\\") as jsonIn\n",
      "    \"with open(path, \\\"w\\\") as jsonOut\n",
      "    \"    with open(escherPath, 'r') as jsonIn\n",
      "    \"df = pd.read_csv('metabolomics differences.csv')\\n\",\n",
      "    \"metabolomics_data = read_csv('metabolomics differences.csv').set_index(\\\"day_diet diff\\\").T.to_dict()\"\n",
      "    \"pathways = read_csv(\\\"AGORA2_pathways.txt\\\", sep=\\\"\\\\t\\\", encoding = \\\"ISO-8859-1\\\")\\n\",\n",
      "    \"    fva_table = read_csv(fva)\\n\",\n",
      "['\\\\\"model_gcf_mapping.json\\\\\"', '\\\\\"AGORA2 to ASV Exact Matches/AGORA2_6_14_23_16S_ASV_to_Genome.json\\\\\"', '\\\\\"unique_asv_mappings.json\\\\\"', '\\\\\"model_gcf_mapping.json\\\\\"', '\\\\\"AGORA2 to ASV Exact Matches/AGORA2_6_14_23_16S_ASV_to_Genome.json\\\\\"', '\\\\\"unique_asv_mappings.json\\\\\"', '\\\\\"reaction_counts_per_asv/{asv}.json\\\\\"', '\\\\\"model_gcf_mapping.json\\\\\"', '\\\\\"unique_asv_mappings.json\\\\\"', '\\\\\"reaction_counts_per_asv/{asv}.json\\\\\"', '\\\\\"reaction_counts_per_asv/all_models.json\\\\\"', '\\\\\"reaction_counts_per_asv/all_models.json\\\\\"', '\\\\\"reaction_counts_per_asv/all_models.json\\\\\"', '\\\\\"./metabolomics data/Bigg_mapped_tms.csv\\\\\"', '\\\\\"../../metabolomics data/complete_mapping_metabolomics.csv\\\\\"', '\\\\\"../../metabolomics data/Bigg_mapped_quantitative_scfa.csv\\\\\"', '\\\\\"../../metabolomics data/wd_meta_merged.csv\\\\\"', '\\\\\"../../metabolomics data/metabolomics_meta.csv\\\\\"', '\\\\\"metabolomics data/all_metabolomic_data.csv\\\\\"', '\\\\\"../../metabolomics data/day_averaged_concentrations_recDay.csv\\\\\"', '\\\\\"../../metabolomics data/day_averaged_concentrations.csv\\\\\"', '\\\\\"/Users/afreiburger/Documents/ModelSEEDpy/examples/Community Modeling/smetana/BiGG_to_MSID.json\\\\\"', '\\\\\"/Users/afreiburger/Downloads/metabolomics_log2_fold_change.csv\\\\\"', '\\\\\"metabolomics data/16s_metadata.csv\\\\\"', '\\\\\"metabolomics data/a1_meta_c1-3.csv\\\\\"', '\\\\\"metabolomics data/mean_abund_perDay_perTreatment_50.csv\\\\\"', '\\\\\"metabolomics data/averaged_asv_values.csv\\\\\"', '\\\\\"metabolomics data/averaged_asv_abundances_interday_mapping.json\\\\\"', '\\\\\"metabolomics data/averaged_asv_abundances_interday_mapping.json\\\\\"', '\\\\\"metabolomics data/metabolomics differences.csv\\\\\"', '\\\\\"solutions.csv\\\\\"', '\\\\\"clade_fluxes.json\\\\\"', '\\\\\"ASVuptakeInteractions.csv\\\\\"', '\\\\\"ASVexcretionInteractions.csv\\\\\"', '\\\\\"ASVgrowthInteractions.csv\\\\\"', '\\\\\"ASVagrowthInteractions.csv\\\\\"', '\\\\\"Sample*.csv\\\\\"', '\\\\\"Sample*.csv\\\\\"', '\\\\\"SamplegrowthInteractions.csv\\\\\"', '\\\\\"SampleagrowthInteractions.csv\\\\\"', '\\\\\"SampleuptakeInteractions.csv\\\\\"', '\\\\\"SampleexcretionInteractions.csv\\\\\"', '\\\\\"/Users/afreiburger/Documents/ModelSEEDpy/examples/Community Modeling/smetana/BiGG_to_MSID.json\\\\\"', '\\\\\"ASVexcretionInteractions.csv\\\\\"', '\\\\\"SampleexcretionInteractions.csv\\\\\"', '\\\\\"ASVexcretion_probInteractions.csv\\\\\"', '\\\\\"Sampleexcretion_probInteractions.csv\\\\\"', '\\\\\"ASVMetaboliteInteractions.csv\\\\\"', '\\\\\"SampleIntervalMetaboliteInteractions.csv\\\\\"', '\\\\\"ASVMetaboliteInteractions.csv\\\\\"', '\\\\\"ASVFluxes.csv\\\\\"', '\\\\\"../../metabolomics data/asv_asvset.json\\\\\"', '\\\\\"../../metabolomics data/asvset_names.json\\\\\"', '\\\\\"named_ASVsets.json\\\\\"', '\\\\\"../../metabolomics data/asvset_names.json\\\\\"', '\\\\\"../../metabolomics data/wd_taxonomy.csv\\\\\"', '\\\\\"new_asv_taxonomy.json\\\\\"', '\\\\\"{baseName}_normalcies.json\\\\\"', '\\\\\"asvname_taxonomy.json\\\\\"', '\\\\\"ASVFluxes2.csv\\\\\"', '\\\\\"SampleIntervalMetaboliteInteractions.csv\\\\\"', '\\\\\"asvname_taxonomy.json\\\\\"', '\\\\\"ASV\\\\\") for asv in glob(\\\\\"ASV*.csv\\\\\"', '\\\\\"../../metabolomics data/day_averaged_concentrations_recDay.csv\\\\\"', '\\\\\"/Users/afreiburger/Documents/ModelSEEDpy/examples/Community Modeling/smetana/BiGG_to_MSID.json\\\\\"', '\\\\\"sample_correlations.json\\\\\"', '\\\\\"sample_prob_correlations.json\\\\\"', '\\\\\"sample_prob_correlations.json\\\\\"', '\\\\\"../../CommScores/commscores/data/compoundNames.json\\\\\"', '\\\\\"../../metabolomics data/day_averaged_concentrations_recDay.csv\\\\\"', '\\\\\"ASVMetaboliteInteractions_names.csv\\\\\"', '\\\\\"metabolomics data/day_averaged_concentrations.csv\\\\\"', '\\\\\"metabolomics data/a1_meta_c1-3.csv\\\\\"', '\\\\\"asvset_asvs.json\\\\\"', '\\\\\"metabolomics data/averaged_asv_abundances_interday_mapping.json\\\\\"', '\\\\\"WesternDietMicrobiomes/escherMap.json\\\\\"', '\\\\\"WesternDietMicrobiomes/escherMap_edited.json\\\\\"', '\\\\\".json\\\\\", \\\\\"_edited.json\\\\\"', '\\\\\"twoRXN_localized.json\\\\\"', '\\\\\"ASVMetaboliteInteractions.csv\\\\\"', '\\\\\"ASV_metabolic_activity_stoich.json\\\\\"', '\\\\\"metabolomics_categories.json\\\\\"', '\\\\\"ASVInteractionModel.json\\\\\"', '\\\\\"ASVInteractionModel_categorizedIDs.json\\\\\"', '\\\\\"metabolite_focused_map.json\\\\\"', '\\\\\"Escher_nodeNum_cpdIDs.json\\\\\"', '\\\\\"EscherNodeMapping.json\\\\\"', '\\\\\"metabolite_focused_map0.json\\\\\"', '\\\\\".json\\\\\", \\\\\"_cleaned0.json\\\\\"', '\\\\\"metabolite_focused_map_IDs_cleaned.json\\\\\"', '\\\\\"metabolite_focused_map_IDs_cleaned0.json\\\\\"', '\\\\\"metabolite_focused_map_IDs_cleaned.json\\\\\"', '\\\\\"ASVInteractionModel.json\\\\\"', '\\\\\"metabolite_focused_map_IDs_cleaned.json\\\\\"', '\\\\\"modelSVG_mapping.json\\\\\"', '\\\\\"TemplateGenome.json\\\\\"', '\\\\\"MetaT/norm.counts.rpk_edger.bins_mean.csv\\\\\"', '\\\\\"MetaT/norm.counts.rpk_edger_geTMM.csv\\\\\"', '\\\\\"clade_fluxes.json\\\\\"', '\\\\\"constraints.json\\\\\"', '\\\\\"constraints.json\\\\\"', '\\\\\"species_reactions.json\\\\\"', '\\\\\"rxnID_subsystem.json\\\\\"', '\\\\\"/Users/afreiburger/Documents/CommScores/commscores/data/MSDB_xRefs.json\\\\\"', '\\\\\"/Users/afreiburger/Documents/CommScores/commscores/data/compoundNames.json\\\\\"']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>line</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./degenerate_models_statistics.ipynb</td>\n",
       "      <td>\"with open(\\\"model_gcf_mapping.json\\\", \\\"w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./degenerate_models_statistics.ipynb</td>\n",
       "      <td>\"with open(\\\"AGORA2 to ASV Exact Matches/A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./degenerate_models_statistics.ipynb</td>\n",
       "      <td>\"with open(\\\"unique_asv_mappings.json\\\", \\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./degenerate_models_statistics.ipynb</td>\n",
       "      <td>\"with open(\\\"model_gcf_mapping.json\\\", \\\"r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./degenerate_models_statistics.ipynb</td>\n",
       "      <td>\"with open(\\\"AGORA2 to ASV Exact Matches/A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>./Pathway_corrections.ipynb</td>\n",
       "      <td>\"        try</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>./Pathway_corrections.ipynb</td>\n",
       "      <td>\"    fva_table = read_csv(fva)\\n\",</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>./Pathway_corrections.ipynb</td>\n",
       "      <td>\"with open(\\\"/Users/afreiburger/Documents/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>./Pathway_corrections.ipynb</td>\n",
       "      <td>\"with open(\\\"/Users/afreiburger/Documents/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>./Pathway_corrections.ipynb</td>\n",
       "      <td>\"with open(\\\"excreta.txt\\\", \\\"w\\\") as Out</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>151 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     file  \\\n",
       "0    ./degenerate_models_statistics.ipynb   \n",
       "1    ./degenerate_models_statistics.ipynb   \n",
       "2    ./degenerate_models_statistics.ipynb   \n",
       "3    ./degenerate_models_statistics.ipynb   \n",
       "4    ./degenerate_models_statistics.ipynb   \n",
       "..                                    ...   \n",
       "146           ./Pathway_corrections.ipynb   \n",
       "147           ./Pathway_corrections.ipynb   \n",
       "148           ./Pathway_corrections.ipynb   \n",
       "149           ./Pathway_corrections.ipynb   \n",
       "150           ./Pathway_corrections.ipynb   \n",
       "\n",
       "                                                  line  \n",
       "0        \"with open(\\\"model_gcf_mapping.json\\\", \\\"w...  \n",
       "1        \"with open(\\\"AGORA2 to ASV Exact Matches/A...  \n",
       "2        \"with open(\\\"unique_asv_mappings.json\\\", \\...  \n",
       "3        \"with open(\\\"model_gcf_mapping.json\\\", \\\"r...  \n",
       "4        \"with open(\\\"AGORA2 to ASV Exact Matches/A...  \n",
       "..                                                 ...  \n",
       "146                                       \"        try  \n",
       "147                 \"    fva_table = read_csv(fva)\\n\",  \n",
       "148      \"with open(\\\"/Users/afreiburger/Documents/...  \n",
       "149      \"with open(\\\"/Users/afreiburger/Documents/...  \n",
       "150          \"with open(\\\"excreta.txt\\\", \\\"w\\\") as Out  \n",
       "\n",
       "[151 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "import re\n",
    "\n",
    "imports = read_csv(\"imports.txt\", sep=\":\")\n",
    "imports.drop(imports.columns[-1], axis=1, inplace=True)\n",
    "\n",
    "# display(imports)\n",
    "\n",
    "imports.loc[-1] = imports.columns\n",
    "imports.index = imports.index + 1\n",
    "imports = imports.sort_index()\n",
    "imports.columns = ['file', 'line']\n",
    "\n",
    "# print(imports[\"line\"][0]) \n",
    "\n",
    "# imports[\"dataFile\"] = []\n",
    "files = []\n",
    "for x in imports[\"line\"]:\n",
    "    if not \"json\" in x and not \"csv\" in x:\n",
    "        # print(x)\n",
    "        pass\n",
    "    elif \"json\" in x:\n",
    "        try:\n",
    "            files.append(re.search(r'(?=\\\\\")(.+)(?<=.json\\\\\")', x).group())\n",
    "        except:\n",
    "            print(x)\n",
    "    elif \"csv\" in x:\n",
    "        try:\n",
    "            files.append(re.search(r'(?=\\\\\")(.+)(?<=.csv\\\\\")', x).group())\n",
    "        except:\n",
    "            print(x)\n",
    "\n",
    "print(files)\n",
    "\n",
    "display(imports)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
